<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Physics Virtuosi</title><link href="/" rel="alternate"></link><link href="http://thephysicsvirtuosi.com/feeds/tag..atom.xml" rel="self"></link><id>/</id><updated>2012-11-29T22:58:00-05:00</updated><entry><title>When will the Earth fall into the Sun?</title><link href="/posts/when-will-the-earth-fall-into-the-sun-.html" rel="alternate"></link><updated>2012-11-29T22:58:00-05:00</updated><author><name>Brian</name></author><id>tag:,2012-11-29:posts/when-will-the-earth-fall-into-the-sun-.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://4.bp.blogspot.com/-_71xzP94MDc/ULgp7n5LP3I/AAAAAAAAACM/WU5UgsRyUYg/s1600/RetardedPic.png"&gt;&lt;img alt="image" src="http://4.bp.blogspot.com/-_71xzP94MDc/ULgp7n5LP3I/AAAAAAAAACM/WU5UgsRyUYg/s200/RetardedPic.png" /&gt;&lt;/a&gt;
  The time I spent making this poster could have been spent doing&amp;nbsp;research.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Since December 2012 is coming up, I thought I&amp;#8217;d help the Mayans out with
a look at a possible end of the world scenario. (I know, it&amp;#8217;s not Earth
Day yet, but we at the Virtuosi can only go so long without fantasizing
about wanton destruction.) As the Earth zips around the Sun, it moves
through the &lt;a href="http://en.wikipedia.org/wiki/Heliosphere"&gt;heliosphere&lt;/a&gt;,
which is a collection of charged particles emitted by the Sun. Like any
other fluid, this will exert drag on the Earth, slowly causing it to
spiral into the Sun. Eventually, it will burn in a blaze of glory, in a
bad-action-movie combination of Sunshine meets Armageddon. Before I get
started, let me preface this by saying that I have no idea what the hell
I&amp;#8217;m talking about. But, in the spirit of being an arrogant physicist,
I&amp;#8217;m going to go ahead and make some back-of-the-envelope calculations,
and expect that this post will be accurate to within a few orders of
magnitude. Well, how long will the Earth rotate around the Sun before
drag from the heliosphere stops it? This seems like a problem for fluid
dynamics. How do we calculate what the drag is on the Earth? Rather than
solve the fluid dynamics equations, let&amp;#8217;s make some arguments based on
dimensional analysis. What can the drag of the Earth depend on? It
certainly depends on the speed of the Earth v &amp;#8212; if an object isn&amp;#8217;t
moving, there can&amp;#8217;t be any drag. We also expect that a wider object
feels more drag, so the drag force should depend on the radius of the
Earth R. Finally, the density of the heliosphere might have something to
do with it. If we fudge around with these, we see that there is only 1
combination that gives units of force: &lt;mathjax&gt;$$ F\_{drag} \\sim \\rho v\^2
R\^2 $$&lt;/mathjax&gt; Now that we have the force, the energy dissipated from the Earth
to the heliosphere after moving a distance &lt;em&gt;d&lt;/em&gt; is &lt;em&gt;E_lost = F*d&lt;/em&gt;. If
the Earth moves with speed v for time t, then we can write &lt;em&gt;E_lost =
F*v*t&lt;/em&gt;. So we can get an idea of the time scale over which the Earth
starts to fall into the Sun by taking &lt;em&gt;E_lost = E_Earth \~ 1/2
M_Earth v\^2&lt;/em&gt;. Rearranging and dropping factors of 1/2 gives &lt;mathjax&gt;$$
T\_\\textrm{Earth burns} \\sim M\_{Earth} v\^2 / (F\_{drag}\\times v)
\\\\ \\qquad \\sim M\_{Earth} / (\\rho R\^2 v) $$&lt;/mathjax&gt; Using the velocity of
the Earth as &lt;em&gt;2*pi *&lt;/em&gt; 1 Astronomical unit/year, Googlin&amp;#8217; for some
numbers, and taking the &lt;a href="http://web.mit.edu/space/www/helio.review/axford.suess.html"&gt;density of the
heliosphere&lt;/a&gt;
to be 10\^-23 g/cc we get&amp;#8230; &lt;mathjax&gt;$$ T \\approx 10\^{19} \\textrm{ years} $$&lt;/mathjax&gt;
Looks like this won&amp;#8217;t be the cause of the Mayan apocalypse. (By
comparison, the &lt;a href="http://en.wikipedia.org/wiki/Sun#Life_cycle"&gt;Sun will burn
out&lt;/a&gt;after only \~10\^9&amp;nbsp;years.)&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Creating an Earth</title><link href="/posts/creating-an-earth.html" rel="alternate"></link><updated>2012-10-27T19:07:00-04:00</updated><author><name>Brian</name></author><id>tag:,2012-10-27:posts/creating-an-earth.html</id><summary type="html">&lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-GIQN6QGw6T8/UIxWmYKvaRI/AAAAAAAAABU/vltgjZeUJus/s1600/116.png"&gt;&lt;img alt="image" src="http://2.bp.blogspot.com/-GIQN6QGw6T8/UIxWmYKvaRI/AAAAAAAAABU/vltgjZeUJus/s200/116.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A while ago I decided I wanted to create something that looks like the
surface of a planet, complete with continents &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; oceans and all. Since
I&amp;#8217;ve only been on a small handful of planets, I decided that I&amp;#8217;d
approximate this by creating something like the Earth on the computer
(without cheating and just copying the real Earth). Where should I
start? Well, let&amp;#8217;s see what the facts we know about the Earth tell us
about how to create a new planet on the computer. &lt;strong&gt;Observation 1&lt;/strong&gt;:
Looking at a map of the Earth, we only see the heights of the surface.
So let&amp;#8217;s describe just the heights of the Earth&amp;#8217;s surface. &lt;strong&gt;Observation
2&lt;/strong&gt;: The Earth is a sphere. So (wait for it) we need to describe the
height on a spherical surface. Now we can recast our problem of making
an Earth more precisely mathematically. We want to know the heights of
the planet&amp;#8217;s surface at each point on the Earth. So we&amp;#8217;re looking for
field (the height of the planet) defined on the surface of a sphere (the
different spots on the planet). Just like a function on the real line
can be expanded in terms of its Fourier components, almost any function
on the surface of a sphere can be expanded as a sum of spherical
harmonics Y&lt;em&gt;lm&lt;/em&gt;. This means we can write the height &lt;em&gt;h&lt;/em&gt; of our planets
surfaces as &lt;mathjax&gt;$$ h(\\theta, \\phi) = \\sum A\_{lm}Y\_l\^m(\\theta, \\phi)
\\quad (1) $$&lt;/mathjax&gt; If we figure out what the coefficients A of the sum should
be, then we can start making some Earths! Let&amp;#8217;s see if we can use some
other facts about the Earth&amp;#8217;s surface to get get a handle on what
coefficients to use. &lt;strong&gt;Observation 3&lt;/strong&gt;: I don&amp;#8217;t know every detail of the
Earth&amp;#8217;s surface, whose history is impossibly complicated. I&amp;#8217;ll capture
this lack-of-knowledge by describing the surface of our imaginary planet
as some sort of random variable. Equation (1) suggests that we can do
this by making the coefficients &lt;em&gt;A&lt;/em&gt; random variables. At some point we
need to make an executive decision on what type of random variable we&amp;#8217;ll
use. For various reasons, &lt;a href="#footnote1"&gt;[1]&lt;/a&gt; I decided I&amp;#8217;d use a Gaussian
random variable with mean 0 and standard deviation &lt;em&gt;alm&lt;/em&gt;: &lt;mathjax&gt;$$ A\_{lm} =
a\_{lm} N(0,1) $$&lt;/mathjax&gt; (Here I&amp;#8217;m using the notation that &lt;em&gt;N(m,v)&lt;/em&gt; is a normal
or Gaussian random variable with mean &lt;em&gt;m&lt;/em&gt; and variance &lt;em&gt;v&lt;/em&gt;. If you
multiply a Gaussian random variable by a constant &lt;em&gt;a&lt;/em&gt;, it&amp;#8217;s the same as
multiplying the variance by &lt;em&gt;a\^2&lt;/em&gt;, so &lt;em&gt;a*N(0,1)&lt;/em&gt; and &lt;em&gt;N(0,a\^2)&lt;/em&gt; are
the same thing.) &lt;strong&gt;Observation 4&lt;/strong&gt;: The heights of the surface of the
Earth are more-or-less independent of their position on the Earth. In
keeping with this, I&amp;#8217;ll try to use coefficients &lt;em&gt;alm&lt;/em&gt; that will give me
a random field that is is isotropic on average. This seems hard at
first, so let&amp;#8217;s just make a hand-waving argument. Looking at some
&lt;a href="http://en.wikipedia.org/wiki/Spherical_harmonics"&gt;pretty pictures&lt;/a&gt; of
spherical harmonics, we can see that each spherical harmonic of degree l
has about l stripes on it, independent of m. So let&amp;#8217;s try using alm&amp;#8217;s
that depend only on l, and are constant if just m changes.
&lt;a href="footnote2"&gt;[2]&lt;/a&gt;. Just for convenience, we&amp;#8217;ll pick this constant to be
&lt;em&gt;l&lt;/em&gt; to some power &lt;em&gt;-p&lt;/em&gt;: &lt;mathjax&gt;$$ a\_{lm} = l\^{-p} \\quad \\textrm{ or} $$&lt;/mathjax&gt;&lt;mathjax&gt;$$
h(\\theta, \\phi) = \\sum\_{l,m} N\_{lm}(0,1) l\^{-p} Y\_l\^m(\\theta,
\\phi) \\quad (2) $$&lt;/mathjax&gt; At this point I got bored &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; decided to see what a
planet would look like if we didn&amp;#8217;t know what value of p to use. So
below is a movie of a randomly generated &amp;#8220;planet&amp;#8221; with a fixed choice of
random numbers, but with the power&lt;em&gt;p&lt;/em&gt;&amp;nbsp;changing.&lt;/p&gt;
&lt;p&gt;As the movie starts (p=0), we see random uncorrelated heights on the
surface &lt;a href="footnote3"&gt;[5]&lt;/a&gt;. As the movie continues and p increases, we see
the surface smooth out rapidly. Eventually, after p=2 or so, the planet
becomes very smooth and doesn&amp;#8217;t look at all like a planet. So the
&amp;#8220;correct&amp;#8221; value for p is somewhere above 0 (too bumpy) and below 2 (too
smooth). Can we use more observations about Earth to predict what a good
value of p should be? &lt;strong&gt;Observation 5&lt;/strong&gt;: The elevation of the Earth&amp;#8217;s
surface exists everywhere on Earth (duh). So we&amp;#8217;re going to need our sum
to exist. How the hell are we going to sum that series though! Not only
is it random, but it also depends on where we are on the planet! Rather
than try to evaluate that sum everywhere on the sphere, I decided that
it would be easiest to evaluate the sum at the &amp;#8220;North Pole&amp;#8221; at
&lt;em&gt;theta=0&lt;/em&gt;. Then, if we picked our coefficients right, this should be
statistically the same as any other point on the planet. Why do we want
to look at &lt;em&gt;theta = 0&lt;/em&gt;? Well, if we look back at the &lt;a href="http://en.wikipedia.org/wiki/Spherical_harmonics"&gt;wikipedia
entry&lt;/a&gt; for spherical
harmonics, we see that &lt;mathjax&gt;$$ Y\_l\^m = \\sqrt{ \\frac{2 l +
1}{4\\pi}\\frac{(l-m)!}{(l+m)!}} e\^{im\\phi}P\^m \_ l(\\cos\\theta)
\\quad (3) $$&lt;/mathjax&gt; That doesn&amp;#8217;t look too helpful &amp;#8212; we&amp;#8217;ve just picked up
another special function Plm that we need to worry about. But there is a
trick with these special functions Plm: at theta = 0, Plm is 0 if m
isn&amp;#8217;t 0, and Pl0 is 1. So at theta = 0 this is simply: &lt;mathjax&gt;$$
Y\_l\^m(\\theta = 0) = \\bigg \\{ \^{\\sqrt{(2l+1)/4\\pi},\\,
m=0}\_{0,\\,m \\ne 0} $$&lt;/mathjax&gt; Now we just have, from every equation we&amp;#8217;ve
written down: &lt;mathjax&gt;$$ h(\\theta = 0) = \\sum\_l \\times l\^{-p} \\times
\\sqrt{(2l+1)/4\\pi }\\times N(0,1) $$&lt;/mathjax&gt;&lt;mathjax&gt;$$ \\quad \\qquad = \\times \\frac
1 {\\sqrt{4\\pi}} \\times \\sum\_l N(0,l\^{-2p}(2l+1)) $$&lt;/mathjax&gt;&lt;mathjax&gt;$$ \\quad
\\qquad = \\times \\frac 1 {\\sqrt{4\\pi}} \\times N(0,\\sum\_l
l\^{-2p}(2l+1) ) $$&lt;/mathjax&gt; &lt;mathjax&gt;$$ \\quad \\qquad = \\times \\frac 1 {\\sqrt{4\\pi}}
\\sqrt{\\sum\_l l\^{-2p}(2l+1)} \\times N(0,1) $$&lt;/mathjax&gt; &lt;mathjax&gt;$$ \\quad \\qquad
\\sim \\sqrt{\\sum\_l l\^{-2p+1}} N(0,1) \\qquad (4) $$&lt;/mathjax&gt; So for the
surface of our imaginary planet to exist, we had better have that sum
converge, or &lt;em&gt;-2p+1 &amp;lt; -1 (p &gt; 1)&lt;/em&gt;. And we&amp;#8217;ve also learned something
else!!! Our model always gives back a Gaussian height distribution on
the surface. Changing the coefficients changes the variance of
distribution of heights, but that&amp;#8217;s all it does to the distribution.
Evidently if we want to get a non-Gaussian distribution of heights, we&amp;#8217;d
need to stretch our surface after evaluating the sum. Well, what does
the height distribution look like from my simulated planets? Just for
the hell of it, I went ahead and generated \~400 independent surfaces at
\~40 different values for the exponent &lt;em&gt;p&lt;/em&gt;, looking at the first 22,499
terms in the series. From these surfaces I reconstructed the measured
distributions; I&amp;#8217;ve combined them into a movie which you can see&amp;nbsp;below.&lt;/p&gt;
&lt;p&gt;As you can see from the movie, the distributions look like Gaussians.
The fits from Eq. (4) are overlaid in black dotted lines. (Since I can&amp;#8217;t
sum an infinite number of spherical harmonics with a computer, I&amp;#8217;ve
plotted the fit I&amp;#8217;d expect from just the terms I&amp;#8217;ve summed. ) As you can
see, they are all close to Gaussians. Not bad. Let&amp;#8217;s see what else we
can get. &lt;strong&gt;Observation 6&lt;/strong&gt;: According to some famous people, the
&lt;a href="http://en.wikipedia.org/wiki/How_Long_Is_the_Coast_of_Britain%3F_Statistical_Self-Similarity_and_Fractional_Dimension"&gt;Earth&amp;#8217;s surface is probably a fractal whose coastlines are
non-differentiable&lt;/a&gt;.
This means that we want a value of p that will make our surface rough
enough so that its gradient doesn&amp;#8217;t exist (the derivative of the sum of
Eq. (2) doesn&amp;#8217;t converge). At this point I&amp;#8217;m getting bored with writing
out calculations, so I&amp;#8217;m just going to make some scaling arguments. From
Eq. (3), we know that each of the spherical harmonics Ylm is related to
a polynomial of degree l in cos(theta). So if we take a derivative, I&amp;#8217;d
expect us to pick up another factor of l each time. Following through
all the steps of Eq. (4) we find &lt;mathjax&gt;$$ \\vec{\\nabla}h \\sim
\\sqrt{\\sum\_l l\^{-2p+3}}\\vec{N}(0,1) \\quad , $$&lt;/mathjax&gt; which converges for
p &gt; 2. So for our planet to be &amp;#8220;fractal,&amp;#8221; we want &lt;em&gt;1&amp;lt;p&amp;lt;2&lt;/em&gt;. Looking at
the first movie, this seems reasonable. &lt;strong&gt;Observation 7&lt;/strong&gt;: 70% of the
Earth&amp;#8217;s surface is under water. On Earth, we can think of the points
underwater as all those points below a certain threshold height. So
let&amp;#8217;s threshold the heights on our sphere. If we want 70% of our
generated planet&amp;#8217;s surface to be under water, Eq (4) and the &lt;a href="http://en.wikipedia.org/wiki/Cumulative_distribution_function"&gt;cumulative
distribution
function&lt;/a&gt;of
a &lt;a href="http://en.wikipedia.org/wiki/Normal_distribution"&gt;Gaussian
distribution&lt;/a&gt; tells us
that we want to pick a critical height &lt;em&gt;H&lt;/em&gt; such that &lt;mathjax&gt;$$ \\frac 1 2
\\left[ 1 + \\textrm{erf}(H/\\sqrt{2\\sigma\^2}) \\right] = 0.7 \\quad
\\textrm{or} $$&lt;/mathjax&gt; &lt;mathjax&gt;$$ H = \\sqrt{2\\sigma\^2}\\textrm{erf}\^{-1}(0.4) $$&lt;/mathjax&gt; &lt;mathjax&gt;$$
\\sigma\^2 = \\frac 1 {4\\pi} \\sum\_l l\^{-2p}(2l+1) \\quad (5)\\, , $$&lt;/mathjax&gt;
where &lt;em&gt;erf()&lt;/em&gt; is a special function called the error function, and erf-1
is its inverse. We can evaluate these numerically (or by using some
&lt;a href="http://en.wikipedia.org/wiki/Error_Function#Asymptotic_expansion"&gt;dirty
tricks&lt;/a&gt;
if we&amp;#8217;re feeling especially masochistic). So for our generated planet,
let&amp;#8217;s call all the points with a height larger than H &amp;#8220;land,&amp;#8221; and all
the points with a height less than H &amp;#8220;ocean.&amp;#8221; Here is what it looks like
for a planet with&lt;em&gt;p=0, p=1&lt;/em&gt;, and &lt;em&gt;p=2&lt;/em&gt;, plotted with the same &lt;a href="http://en.wikipedia.org/wiki/Sinusoidal_projection"&gt;Sanson
projection&lt;/a&gt; as&amp;nbsp;before.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-bWQBhSTYGAc/UIxZyk1d9dI/AAAAAAAAABk/FSZtM2jZ24g/s1600/allContinents.png"&gt;&lt;img alt="image" src="http://1.bp.blogspot.com/-bWQBhSTYGAc/UIxZyk1d9dI/AAAAAAAAABk/FSZtM2jZ24g/s400/allContinents.png" /&gt;&lt;/a&gt;
  Top to bottom: p=0, p=1, and p=2. I&amp;#8217;ve colored all the &amp;#8220;water&amp;#8221; (positions with heights &amp;lt; &lt;em&gt;H&lt;/em&gt;as given in Eq. (5) ) blue and all the land (heights &gt; &lt;em&gt;H&lt;/em&gt;)&amp;nbsp;green.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;You can see that the the total amount of land area is roughly constant
among the three images, but we haven&amp;#8217;t fixed how it&amp;#8217;s distributed.
Looking at the map above for &lt;em&gt;p=0&lt;/em&gt;, there are lots of small &amp;#8220;islands&amp;#8221;
but no large contiguous land masses. For &lt;em&gt;p=2&lt;/em&gt;, we see only one
contiguous land mass (plus one 5-pixel island), and &lt;em&gt;p=1&lt;/em&gt; sits somewhere
in between the two extremes. None of these look like the Earth, where
there are a few large landmasses but many small islands. From our
previous arguments, we&amp;#8217;d expect something between p=1 and p=2 to look
like the Earth, which is in line with the above picture. But how do we
decide which value of p to use? &lt;strong&gt;Observation 8&lt;/strong&gt;: The Earth has 7
continents This one is more vague than the others, but I think it&amp;#8217;s the
coolest of all the arguments. How do we compare our generated planets to
the Earth? The Earth has 7 continents that comprise 4 different
contiguous landmasses. In order, these are 1) Europe-Asia-Africa, 2)
North- and South- America, 3) Antartica, and 4) Australia, with a 5th
Greenland barely missing out. In terms of fractions of the Earth&amp;#8217;s
surface, Google tells us that Australia covers 0.15% of the Earth&amp;#8217;s
total surface area, and Greenland covers 0.04%. So let&amp;#8217;s define a
&amp;#8220;continent&amp;#8221; as any contiguous landmass that accounts for more than 0.1%
of the planet&amp;#8217;s total area. Then we can ask: What value of &lt;em&gt;p&lt;/em&gt; gives us
a planet with 4 continents? I have no idea how to calculate exactly what
that number would be from our model, but I can certainly measure it from
the simulated results. I went ahead and counted the number of continents
in the generated&amp;nbsp;planets.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://3.bp.blogspot.com/-eGMLLNCMVRU/UIxbi6MYw9I/AAAAAAAAAB8/BFVHUaEctBA/s1600/numContinents.png"&gt;&lt;img alt="image" src="http://3.bp.blogspot.com/-eGMLLNCMVRU/UIxbi6MYw9I/AAAAAAAAAB8/BFVHUaEctBA/s400/numContinents.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-W3qT-_LOlT4/UIxaxqd1b9I/AAAAAAAAABs/HZEMht7uzlU/s1600/numContinents.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The results are plotted above. The solid red line is the median values
of the number of continents, as measured over 400 distinct worlds at 40
different values of p. The red shaded region around it is the band
containing the upper and lower quartiles of the number of continents.
For comparison, in black on the right y-axis I&amp;#8217;ve also plotted the log
of the total number of landmasses at the resolution I&amp;#8217;ve used. The
number of continents has a resonant value of p &amp;#8212; if p is too small,
then there are many landmasses, but none are big enough to be
continents. Conversely, if p is too large, then there is only one huge
landmass. Somewhere in the middle, around p=0.5, there are about 20
continents, at least when only the first \~23000 terms in the series are
summed. Looking at the curve, we see that there are roughly two places
where there are 4 continents in the world &amp;#8212; at p=0.1 and at p=1.3.
Since p=0.1 doesn&amp;#8217;t converge, and since p=0.1 will have way too many
landmasses, it looks like a generated Earth will look the best if we use
a value of &lt;em&gt;p=&lt;/em&gt;1.3 And that&amp;#8217;s it. For your viewing pleasure, here is a
video of three of these planets below, complete with water, continents,
and mountains. &lt;a href="footnote4"&gt;[4]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[1] Since I wanted a random surface, I wanted to make the mean of each
coefficient 0. Otherwise we&amp;#8217;d get a deterministic part of our surface
heights. I picked a distribution that&amp;#8217;s symmetric about 0 because on
Earth the bottom of the oceans seem roughly similar in terms of changes
in elevation. I wanted to pick a stable distribution &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; independent
coefficients because it makes the sums that come up easier to evalutate.
Finally, I picked a Gaussian, as opposed to another stable distribution
like a Lorentzian, because the tallest points on Earth are finite, and I
wanted the variance of the planet&amp;#8217;s height to be&amp;nbsp;defined.&lt;/p&gt;
&lt;p&gt;[2] We could make this rigorous by showing that a rotated spherical
harmonic is orthogonal to other spherical harmonics of a different
degree &lt;em&gt;l&lt;/em&gt;, but you don&amp;#8217;t want to see me&amp;nbsp;try.&lt;/p&gt;
&lt;p&gt;[3]Actually p=0 should correspond to completely uncorrelated
delta-function noise. (You can convince yourself by looking at the
spherical harmonic expansion for a delta-function.) The reason that the
bumps have a finite width is that I only summed the first 22,499 terms
in the series (l=150 and below). So the size of the bumps gives a rough
idea of my&amp;nbsp;resolution.&lt;/p&gt;
&lt;p&gt;[4] For those of you keeping score at home, it took me more than 6 days
to figure out how to make these&amp;nbsp;planets.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>A Homemade Viscometer I</title><link href="/posts/a-homemade-viscometer-i.html" rel="alternate"></link><updated>2012-07-24T22:32:00-04:00</updated><author><name>Brian</name></author><id>tag:,2012-07-24:posts/a-homemade-viscometer-i.html</id><summary type="html">&lt;p&gt;Stirring a bowl of honey is much more difficult than stirring a bowl of
water. But why? The mass density of the honey is about the same as that
of water, so we aren&amp;#8217;t moving more material. If we were to write out
Newton&amp;#8217;s equation, &lt;em&gt;ma&lt;/em&gt; would be about the same, but yet we still need
to put in much more force. Why? And can we measure it? The reason that
honey is harder to stir is of course that the drag on our spoon depends
on more than just the density of the fluid. The drag also depends on the
viscosity of the fluid &amp;#8212; loosely speaking, how thick it is &amp;#8212; and the
viscosity of honey is about 400 times that of water, depending on the
conditions. In fact, a quick perusal of the Wikipedia article on
&lt;a href="http://en.wikipedia.org/wiki/Viscosity"&gt;viscosity&lt;/a&gt; shows that
viscosities can vary by a fantastic amount &amp;#8212; some 13 orders of
magnitude, from easy-to-move gases to &lt;a href="http://en.wikipedia.org/wiki/Pitch_drop_experiment"&gt;thick pitch that behaves like a
solid except&lt;/a&gt; on
long time scales. The situation is even more complicated than this, as
some fluids can have a &lt;a href="http://en.wikipedia.org/wiki/Non-Newtonian_fluid"&gt;viscosity that changes depending on the
flow&lt;/a&gt;. I wanted to
find a way to measure the viscosities of the stuff around me, so I made
the &lt;a href="http://en.wikipedia.org/wiki/Viscometer"&gt;viscometer&lt;/a&gt; pictured below
for about $1.75 (the vending machines in Clark Hall are pretty
expensive). How? Well,&amp;nbsp;I&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-3R2mNiV_-KY/UA4pOLSKLSI/AAAAAAAAABA/X4MHVcrh93M/s1600/DSCF4438.JPG"&gt;&lt;img alt="image" src="http://1.bp.blogspot.com/-3R2mNiV_-KY/UA4pOLSKLSI/AAAAAAAAABA/X4MHVcrh93M/s400/DSCF4438.JPG" /&gt;&lt;/a&gt;
  My homemade viscometer, taking data on the viscosity of&amp;nbsp;water.&lt;/p&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li&gt;Enjoyed the crisp, refreshing taste of Diet Pepsi from a 20 oz
    bottle (come on,&amp;nbsp;sponsorships).&lt;/li&gt;
&lt;li&gt;Cut the top and bottom off the bottle, so all that was left was a
    straight&amp;nbsp;tube.&lt;/li&gt;
&lt;li&gt;Mounted the bottle with on top of a small piece of flat&amp;nbsp;plastic.&lt;/li&gt;
&lt;li&gt;Mounted a single-tubed coffee stirrer horizontally out of the bottle
    (I placed the end towards the middle of the bottle to avoid end&amp;nbsp;effects).&lt;/li&gt;
&lt;li&gt;Epoxied or glued the entire edge&amp;nbsp;shut.&lt;/li&gt;
&lt;li&gt;Marked evenly-spaced lines on the side of the&amp;nbsp;bottle.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I can load my &amp;#8220;sample&amp;#8221; fluid in the top of the Pepsi bottle, and time
how long it takes for the sample level to drop to a certain point. A
more viscous fluid will take more time to leave the bottle, with the
time directly proportional to the viscosity. (This is a consequence of
Stokes flow and the equation for flow in a pipe. It will always be true,
as long as my fluid is viscous enough and my apparatus isn&amp;#8217;t too big.)
So we&amp;#8217;re done! All we need to do is calibrate our viscometer with one
sample, measure the times, and then we can go out and measure stuff in
the world! No need to stick around for the boring calculations! We can
do some fun science over the next few blog posts! But this is a physics
blog written by a bunch of grad students, so I&amp;#8217;m assuming that a few of
you want to see the details. (I won&amp;#8217;t judge you if you don&amp;#8217;t though.) If
we think about the problem for a bit, we basically have flow of a liquid
through a pipe (i.e. the coffee stirrer), plus a bunch of other crap
which hopefully doesn&amp;#8217;t matter much. We first need to think about how
the fluid moves. We want to find the velocity of the fluid at every
position. This is best cast in the language of vector calculus &amp;#8212; we
have a (vector) velocity field &lt;strong&gt;&lt;em&gt;u&lt;/em&gt;&lt;/strong&gt; at a (vector) position &lt;strong&gt;&lt;em&gt;x&lt;/em&gt;&lt;/strong&gt;.
There are two things we know: 1) We don&amp;#8217;t (globally) gain or lose any
fluid, and 2) Newton&amp;#8217;s laws &lt;em&gt;F=ma&lt;/em&gt; hold. We can write these equations as
the Navier-Stokes equations: &lt;mathjax&gt;$$ \\vec{\\nabla}\\cdot \\vec{u} = 0 \\quad
(1) $$&lt;/mathjax&gt; &lt;mathjax&gt;$$ \\ \\rho \\left( \\frac {\\partial \\vec{u}} {\\partial t} +
(\\vec{u}\\cdot\\vec{\\nabla})\\vec{u} \\right) = - \\vec{\\nabla}p +
\\eta \\nabla\^2 \\vec{u} \\quad (2) $$&lt;/mathjax&gt; The first equation basically
says that we don&amp;#8217;t have any fluid appearing or disappearing out of
nowhere, and the second is basically &lt;em&gt;m&lt;strong&gt;a&lt;/strong&gt;=&lt;strong&gt;F&lt;strong&gt;&lt;em&gt;, except written per
unit volume. (The fluid&amp;#8217;s mass-per-unit-volume is &lt;em&gt;rho&lt;/em&gt;, the rate of
change of our velocity is &lt;em&gt;d&lt;strong&gt;u&lt;/strong&gt;/dt&lt;/em&gt;, and our force per unit volume is&lt;/em&gt;&lt;/strong&gt;grad&lt;/strong&gt;(p)&lt;/em&gt;, plus a viscous term &lt;em&gt;laplacian(&lt;strong&gt;u&lt;/strong&gt;)&lt;/em&gt;. The only
complication is that &lt;em&gt;d&lt;strong&gt;u&lt;/strong&gt;/dt&lt;/em&gt; is a total derivative, which we need to
write as &lt;em&gt;d&lt;strong&gt;u&lt;/strong&gt;/dt + d&lt;strong&gt;u&lt;/strong&gt;/d&lt;strong&gt;x&lt;/strong&gt;*d&lt;strong&gt;x&lt;/strong&gt;/dt&lt;/em&gt;.) I won&amp;#8217;t drag you
through the &lt;a href="http://www.4shared.com/office/y9ay-fNh/Homemade_viscometer_-gory_sect.html?refurl=d1url"&gt;gory
details&lt;/a&gt;,
unless you want to see them, but it turns out that for my system the
height of the fluid &lt;em&gt;h&lt;/em&gt; (measured from the coffee stirrer) versus time
&lt;em&gt;t&lt;/em&gt; is &lt;mathjax&gt;$$ h(t) = h(0)e\^{- t/T}, \\quad T= 60.7 \\textrm{sec} \\times
[\\eta / \\textrm{1 mPa\*s}] \\times [\\textrm{ 1 g/cc} / \\rho] $$&lt;/mathjax&gt; [For
my viscometer, the coffee stirrer has length 13.34 cm and inside
diameter 2.4 mm, and the Pepsi bottle has a cross-sectional area of 36.3
square centimeters (3.4 cm inner radius). You can see how the timescale
scales with these properties in the &lt;a href="http://www.4shared.com/office/y9ay-fNh/Homemade_viscometer_-gory_sect.html?refurl=d1url"&gt;gory details
section&lt;/a&gt;.]&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-RsGC2KaafVA/UA4pwpCbz6I/AAAAAAAAABI/S740sriRWg4/s1600/5.png"&gt;&lt;img alt="image" src="http://1.bp.blogspot.com/-RsGC2KaafVA/UA4pwpCbz6I/AAAAAAAAABI/S740sriRWg4/s400/5.png" /&gt;&lt;/a&gt;
  A run with measured heights vs times &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; error bars. The majority of the uncertainty turns out to come from not knowing the exact proportions of the viscometer. I don&amp;#8217;t know exactly why the heights are systematically deviating from the fit, but I suspect it&amp;#8217;s that my gridlines aren&amp;#8217;t perfectly lined up with the bottom of my viscometer (it looks like \~5 mm off would do it, which I can totally believe looking at the picture of my viscometer). However, because of the linearity of the equations for steady flow in a pipe, we know that the time scales linearly with the viscosity, so we should be able to accurately measure relative&amp;nbsp;viscosities.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Well, how well does it work? Above is a plot of the height of water in
my viscometer versus time, with a best-fit value from the equations
above. To get a sense of my random errors (such as how good I am at
timing the flow), I measured this curve 5 separate times. If I take into
account the uncertainties in my apparatus setup as systematic errors, I
find a value for my viscosity as &lt;mathjax&gt;$$ \\eta \\approx 1.429 \\textrm{mPa\*
s} \\pm 0.5 \\% \\textrm{Rand.} \\pm 55\\% \\textrm{Syst.} $$&lt;/mathjax&gt; The actual
value of the viscosity of water at room temperature (T=25 C) is about
0.86 mPa*s, which is more-or-less within my systematic errors. So it
looks like I won&amp;#8217;t be able to measure absolute values of viscosity
accurately without a more precise apparatus. But if I look at the
variation of my measured viscosity, I see that I should probably be able
to measure changes in viscosity to 0.5% !! That&amp;#8217;s pretty good! Hopefully
over the next couple weeks I&amp;#8217;ll try to use my viscometer to measure some
interesting physics in the viscosity of&amp;nbsp;fluids.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>How Cold is the Ground II</title><link href="/posts/how-cold-is-the-ground-ii.html" rel="alternate"></link><updated>2012-05-26T21:28:00-04:00</updated><author><name>Brian</name></author><id>tag:,2012-05-26:posts/how-cold-is-the-ground-ii.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://4.bp.blogspot.com/-NE8upI-YG1I/T8F4TvyfkyI/AAAAAAAAAA0/YmQ_KLlOseA/s1600/mainImage.png"&gt;&lt;img alt="image" src="http://4.bp.blogspot.com/-NE8upI-YG1I/T8F4TvyfkyI/AAAAAAAAAA0/YmQ_KLlOseA/s200/mainImage.png" /&gt;&lt;/a&gt;
  Images &lt;a href="http://en.wikipedia.org/wiki/File:Ithaca_Hemlock_Gorge.JPG"&gt;from&lt;/a&gt;&lt;a href="http://en.wikipedia.org/wiki/File:Mercury_in_color_-_Prockter07_centered.jpg"&gt;Wikipedia&lt;/a&gt;                                           &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Last week (ok, it was a little more than a few days ago&amp;#8230;.) I used
dimensional analysis to figure out how the ground&amp;#8217;s temperature changes
with time. But although dimensional analysis can give us information
about the length scales in the problem, it doesn&amp;#8217;t tell us what the
solution looks like. From dimensional analysis, we don&amp;#8217;t even know what
the solution does at large times and distances. (Although we can usually
see the asymptotic behavior directly from the equation.) So let&amp;#8217;s go
ahead and solve the the heat equation exactly: &lt;mathjax&gt;$$ \\frac {\\partial
T}{\\partial t} = a \\frac {\\partial \^2 T}{\\partial x\^2} \\quad (1)
$$&lt;/mathjax&gt; Well, what type of solution do we want to this equation? We want the
temperature at the Earth&amp;#8217;s surface &lt;em&gt;x=0&lt;/em&gt; to change with the days or the
seasons. So let&amp;#8217;s start out modeling this with a sinusoidal dependence
&amp;#8212; we&amp;#8217;ll look for a solution of the form &lt;mathjax&gt;$$ T(x,t) = A(x)e\^{i wt} $$&lt;/mathjax&gt;
for some function &lt;em&gt;A(x)&lt;/em&gt;, then we can take the real part for our
solution. Plugging this into Eq. (1) gives &lt;em&gt;A&amp;#8221; = iw/a * A&lt;/em&gt;, or &lt;mathjax&gt;$$ A(x)
= e\^{ \\pm \\sqrt{w/2a } (1+i) x} $$&lt;/mathjax&gt; Since we have a second-order
ordinary differential equation for &lt;em&gt;A&lt;/em&gt;, we have two possible solutions,
which are like &lt;em&gt;exp(+x)&lt;/em&gt;or &lt;em&gt;exp(-x)&lt;/em&gt;. Which one do we choose? Well, we
want the temperature very far away from the surface of the ground to be
constant, so we need the solution that decays with distance,
&lt;em&gt;A\~exp(-x)&lt;/em&gt;. Taking the real part of this solution, we find
&lt;a href="#footnote-1"&gt;[1]&lt;/a&gt; &lt;mathjax&gt;$$T(x,t) = T\_0 \\cos (wt + \\sqrt{w/2a}\\times x )
e\^{-\\sqrt{w/2a}x} \\quad (2) $$&lt;/mathjax&gt; Well, what does this solution &lt;em&gt;say&lt;/em&gt;?
As we expected from our scaling arguments last week, the distance scale
depends on the &lt;em&gt;square root&lt;/em&gt; of the time scale &amp;#8212; if we decrease our
frequency by 4 (say, looking at changes over a season vs over a month),
the ground gets cooler only 2x deeper. We also see that the temperature
oscillation drops off quite rapidly as we go deeper into the ground, and
that there is a &amp;#8220;lag&amp;#8221; the farther you go into the ground. In particular,
we see that at distances deep into the ground, the temperature drops to
its average value at the surface. You can see this all in the pretty
plot below (generated with&amp;nbsp;Python):&lt;/p&gt;
&lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-sqMX0J6IxWE/T8FWTQUcMQI/AAAAAAAAAAM/_esX_l0VLjs/s1600/SingleFrequency.png"&gt;&lt;img alt="image" src="http://2.bp.blogspot.com/-sqMX0J6IxWE/T8FWTQUcMQI/AAAAAAAAAAM/_esX_l0VLjs/s400/SingleFrequency.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s recap. To model the temperature of the ground, we looked for a
solution to the heat equation which had a sinusoidally oscillating
temperature at &lt;em&gt;x=0&lt;/em&gt;, and decayed to 0 at large &lt;em&gt;x&lt;/em&gt;. We found a solution
such a solution, and it shows that the temperature decays rapidly as we
go far into the ground. At this point, there are two questions that pop
into mind: 1) Is the solution that we found &lt;em&gt;unique&lt;/em&gt;? Or are there other
possible solutions? 2) This is all well and good, but what if our days
or seasons &lt;em&gt;aren&amp;#8217;t perfect sines&lt;/em&gt;? Can we find a solution that describes
this behavior? I&amp;#8217;ll give one (1) VirtuosiPoint to the first commenter
who can prove to what extent the above solution is unique
&lt;a href="#footnote-2"&gt;[2]&lt;/a&gt;. But how about the second point? Can we solve this
for non-sinusoidal time variations? Well, at this point most of the
readers are rolling their eyes and shouting &amp;#8220;Use a &lt;a href="http://en.wikipedia.org/wiki/Fourier_series"&gt;Fourier
series&lt;/a&gt; and move on.&amp;#8221; So I
will. Briefly, it turns out that (more or less) &lt;em&gt;any&lt;/em&gt; periodic function
can be written as a sum of sines &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; cosines. So we can just add a bunch
of sines and cosines together and construct our final solution. So just
for fun, here is a plot of the temperature of the ground in Ithaca (data
from &lt;a href="http://en.wikipedia.org/wiki/Ithaca,_New_York"&gt;Wikipedia&lt;/a&gt;) over a
year. (I used a discrete Fourier transform to compute the&amp;nbsp;coefficients.)&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://4.bp.blogspot.com/-sYVDb4CwX9I/T8F4KNeQuqI/AAAAAAAAAAs/K12tb4CCrpc/s1600/IthacaTemp.png"&gt;&lt;img alt="image" src="http://4.bp.blogspot.com/-sYVDb4CwX9I/T8F4KNeQuqI/AAAAAAAAAAs/K12tb4CCrpc/s400/IthacaTemp.png" /&gt;&lt;/a&gt;
  The temperature (colorbar) is in degrees C, assuming &lt;a href="http://thevirtuosi.blogspot.com/2012/05/how-cold-is-ground.html"&gt;&lt;em&gt;a=0.5 mm\^2/s&lt;/em&gt;.&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-hNPxXpFwZag/T8F30BJbujI/AAAAAAAAAAk/v6Y4pzilvao/s1600/IthacaTemp.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty boring, but I swear that all the frequencies are in that
plot. It just turns out that the seasons in Ithaca are pretty
sinusoidal. So about 20 meters below Ithaca, the temperature is a pretty
constant 8 C. While I was postponing writing this, I wondered what the
temperature on Mercury&amp;#8217;s rocks would be. If we dig deep enough, can we
find an area with habitable temperatures? Some
&lt;a href="http://hypertextbook.com/facts/2000/OlesyaNisanov.shtml"&gt;quick&lt;/a&gt;&lt;a href="http://en.wikipedia.org/wiki/Mercury_%28planet%29#Surface_conditions_and_.22atmosphere.22_.28exosphere.29"&gt;Googlin&lt;/a&gt;&amp;#8216;
shows that the daytime and nighttime temperatures on Mercury are
\~550-700 K and \~110 K at the &amp;#8220;equator.&amp;#8221; While I don&amp;#8217;t think that
Mercury&amp;#8217;s temperature varies symmetrically, let&amp;#8217;s assume so for lack of
better data.&lt;a href="#footnote-3"&gt;[3]&lt;/a&gt; Then we&amp;#8217;d expect that deep into the
surface, the temperature would be fairly constant in time, at the
average of these two extremes. Plugging in the numbers (assuming
&lt;em&gt;a\~0.52 mm\^2/s&lt;/em&gt; and using a Mercurial solar day as 176 days), we&amp;nbsp;get&lt;/p&gt;
&lt;p&gt;&lt;em&gt;T=94&lt;/em&gt;C, at 2.75 meters into the&amp;nbsp;surface.&lt;/p&gt;
&lt;p&gt;[1] More precisely, since the heat equation is linear and real, if
&lt;em&gt;T(x,t)&lt;/em&gt;is a solution to the equation, then so are &lt;em&gt;1/2(T+T*)&lt;/em&gt; or
&lt;em&gt;1/2i(T-T*).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;[2] Hint: It&amp;#8217;s not unique. For instance, here is another solution that
satisfies the constraints, with no internal heat sources or sinks (I&amp;#8217;ll
call it the &amp;#8220;freshly buried&amp;#8221;&amp;nbsp;solution):&lt;/p&gt;
&lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-KiwBKp4WarU/T8FdnaHDloI/AAAAAAAAAAY/naHre8kRVIQ/s1600/buriedAlive.png"&gt;&lt;img alt="image" src="http://2.bp.blogspot.com/-KiwBKp4WarU/T8FdnaHDloI/AAAAAAAAAAY/naHre8kRVIQ/s320/buriedAlive.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Can you prove that all the other solutions decay to the original
solution? Or is there a second or even a spectrum of steady state&amp;nbsp;solutions?&lt;/p&gt;
&lt;p&gt;[3] If someone provides me with better data of the time variation of
Mercury&amp;#8217;s surface at some specific latitude, I&amp;#8217;ll update with a full
plot of the temperature as a function of depth and&amp;nbsp;time.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>How Cold is the Ground?</title><link href="/posts/how-cold-is-the-ground-.html" rel="alternate"></link><updated>2012-05-18T00:20:00-04:00</updated><author><name>Brian</name></author><id>tag:,2012-05-18:posts/how-cold-is-the-ground-.html</id><summary type="html">&lt;p&gt;It snowed in Ithaca a few weeks ago. Which sucked. But fortunately, it
had been warm for the previous few days, and the ground was still warm
so the snow melted fast. Aside from letting me enjoy the absurd
arguments against global warming that snow in April birthed, this got me
thinking: How cold is the ground throughout the year? At night vs.
during the day? And the corollary: How cold is my basement? If I dig a
deeper basement, can I save on heating and cooling? (I&amp;#8217;m very cheap.)
Well, we want to know the temperature distribution &lt;em&gt;T&lt;/em&gt; of the ground as
a function of time &lt;em&gt;t&lt;/em&gt; and position &lt;em&gt;x&lt;/em&gt;. So some googlin&amp;#8217; or previous
knowledge shows that we need to solve the &lt;a href="http://en.wikipedia.org/wiki/Heat_equation"&gt;heat
equation&lt;/a&gt;. For our purposes,
we can treat the Earth as flat (I don&amp;#8217;t plan on digging a basement deep
enough to see the curvature of the Earth), so we can assume the
temperature only changes with the depth into the ground &lt;em&gt;x&lt;/em&gt;: &lt;mathjax&gt;$$ \\frac
{\\partial T}{\\partial t} = a \\frac {\\partial\^2 T} {\\partial x\^2}
\\qquad (1) $$&lt;/mathjax&gt; where &lt;em&gt;a&lt;/em&gt; is the thermal diffusivity of the material, in
units of square meters per second. It looks like we&amp;#8217;re going to have to
solve some partial differential equations! Or will we? We can get a very
good estimate of how much the temperature changes with depth just by
dimensional analysis. Let&amp;#8217;s measure our time &lt;em&gt;t&lt;/em&gt; in terms of a
characteristic time of our problem &lt;em&gt;w&lt;/em&gt; (it could be 1 year if we were
trying to see the change in the ground&amp;#8217;s temperature from summer to
winter, or 1 day if we were looking at the change from day to night).
Then we can write: &lt;mathjax&gt;$$ \\frac {\\partial T } {\\partial t} = \\frac 1 w
\\frac {\\partial T} {\\partial t/w} $$&lt;/mathjax&gt; &amp;#8230; plugging this in Eq. (1),
rearranging, and calling &lt;em&gt;l&lt;/em&gt;= sqrt(&lt;em&gt;w*a&lt;/em&gt;) gives&amp;#8230;. &lt;mathjax&gt;$$ \\frac
{\\partial T}{\\partial (t/w)} = \\frac {\\partial \^2 T} {\\partial (x/
l )\^2} $$&lt;/mathjax&gt; Now let&amp;#8217;s say we didn&amp;#8217;t know how to or didn&amp;#8217;t want to solve
this equation. (Don&amp;#8217;t worry, we do &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; we will). From rearranging this
equation, we see right away there is only one &amp;#8220;length scale&amp;#8221; in the
problem, &lt;em&gt;l&lt;/em&gt;. So if we had to guess, we could guess that the ground
changes temperature a distance &lt;em&gt;l&lt;/em&gt; into the ground. A quick look at
Wikipedia for &lt;a href="http://en.wikipedia.org/wiki/Thermal_diffusivity"&gt;thermal
diffusivities&lt;/a&gt; gives
us the following table, for materials we&amp;#8217;d find in the ground:
Material
&lt;em&gt;a&lt;/em&gt;, mm\^2/s
&lt;em&gt;l&lt;/em&gt; (cm), &lt;em&gt;w&lt;/em&gt; = 1 day
&lt;em&gt;l&lt;/em&gt; (cm), &lt;em&gt;w&lt;/em&gt; = 1 year
Polycrystalline Silica (glass, sand)
0.83
27 cm
5.1 meters
Crystalline Silica (quartz)
1.4
35
6.6
Sandstone
1.15
32
6.0
Brick
0.52
21
4.0
&lt;a href="http://soilphysics.okstate.edu/software/SoilTemperature/document.pdf"&gt;Soil&lt;/a&gt;
0.3-1.25
16-33
3.1-6.3
So we would expect that the temperature of the ground doesn&amp;#8217;t change
much on a daily basis a foot or so below the ground, and doesn&amp;#8217;t change
ever about 15-20 feet into the ground. Just to pat ourselves on the back
for our skills at dimensional analysis, a quick check shows that
&lt;a href="http://en.wikipedia.org/wiki/Permafrost#Time_to_form_deep_permafrost"&gt;permafrost&lt;/a&gt;
penetrates 14.6 feet into the ground after 1 year. So our dimensional
estimates looks pretty good! In the next few days I&amp;#8217;ll solve this
equation exactly and throw up a few pretty graphs, and maybe talk a
little about &lt;span class="caps"&gt;PDE&lt;/span&gt;&amp;#8217;s and Fourier series in the&amp;nbsp;process.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>End of the Earth VII: The Big Freeze</title><link href="/posts/end-of-the-earth-vii-the-big-freeze.html" rel="alternate"></link><updated>2012-04-22T19:34:00-04:00</updated><author><name>Jesse</name></author><id>tag:,2012-04-22:posts/end-of-the-earth-vii-the-big-freeze.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-c8vJR4CVwZc/T5R7_62SLuI/AAAAAAAAAHU/POCT5Fhx-CQ/s1600/Space_Scene_Frozen_Earth_WP_BG_by_PimArt.jpg"&gt;&lt;img alt="image" src="http://1.bp.blogspot.com/-c8vJR4CVwZc/T5R7_62SLuI/AAAAAAAAAHU/POCT5Fhx-CQ/s320/Space_Scene_Frozen_Earth_WP_BG_by_PimArt.jpg" /&gt;&lt;/a&gt;&amp;nbsp;http://tinyurl.com/7rdj996&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;It is traditional here at The Virtuosi to
&lt;a href="http://thevirtuosi.blogspot.com/2010/04/end-of-earth-physics-i.html"&gt;plot&lt;/a&gt;
&lt;a href="http://thevirtuosi.blogspot.com/2010/04/end-of-earth-ii-blaze-of-glory.html"&gt;the&lt;/a&gt;
&lt;a href="http://thevirtuosi.blogspot.com/2010/04/end-of-earth-physics-iii-asteroids.html"&gt;destruction&lt;/a&gt;
&lt;a href="http://thevirtuosi.blogspot.com/2011/04/end-of-earth-iv-shocking-destruction.html"&gt;of&lt;/a&gt;
&lt;a href="http://thevirtuosi.blogspot.com/2011/04/end-of-earth-v-there-goes-sun.html"&gt;the&lt;/a&gt;
&lt;a href="http://thevirtuosi.blogspot.com/2011/04/end-of-earth-vi-nanobot-destruction.html"&gt;earth&lt;/a&gt;.
We also are making secret plans for our volcano lair and death ray.
However, since it is earth day, we will only share with you the plans
for the total doom of the earth, not the cybernetically enhanced guard
dogs we&amp;#8217;re building for our &lt;a href="http://thevirtuosi.blogspot.com/2012/04/earth-day-2012-escape-to-moon.html"&gt;moon
base&lt;/a&gt;.
The plan I reveal today is elegant in its simplicity. I intend to alter
the orbit of the earth enough to cause the earth to freeze, thus ending
life as we know it. According to the internet at large, the average
surface temperature of the earth is \~15 C. This average surface
temperature is directly related to the power output of the sun. More
precisely, it is directly related to the radiated power from the sun
that the earth absorbs. Assuming that the earth&amp;#8217;s temperature is not
changing (true enough for our purposes), the then power radiated by the
earth must be equal to the power absorbed from the sun. More precisely
&lt;mathjax&gt;$$ P\_{rad,earth}=P\_{abs,sun}$$&lt;/mathjax&gt; Now, the radiated power goes as
&lt;mathjax&gt;$$P\_{rad}=\\epsilon \\sigma A\_{earth} T\^4 $$&lt;/mathjax&gt; where A_earth is the
surface area of the earth, T is the temperature of the earth, and
epsilon and sigma are constants. I&amp;#8217;ll be conservative and say that I
want to cool the temperature of the earth down to 0 C. The ratio of the
power the earth will emit is
&lt;mathjax&gt;$$\\frac{P\_{new}}{P\_{old}}=\\frac{T\_{new}\^4}{T\_{old}\^4} \\approx
.81$$&lt;/mathjax&gt; Note that the temperature ratio must be done in Kelvin. The power
radiated by the sun (or any star) drops off as the inverse square of the
distance from the sun to the point of interest: &lt;mathjax&gt;$$P\_{sun} \\sim
\\frac{1}{r\^2} $$&lt;/mathjax&gt; To reduce the power the earth receives from the sun
to 81% of the current value would require
&lt;mathjax&gt;$$\\frac{P\_{sun,new}}{P\_{sun,old}}=\\frac{r\_{old}\^2}{r\_{new}\^2}=.81
$$&lt;/mathjax&gt; This tells us that the new earth-sun distance must be larger than the
old (a good sanity check). In fact, it gives &lt;mathjax&gt;$$r\_{new}=1.11 r\_{old} $$&lt;/mathjax&gt;
So I&amp;#8217;ll need to move the earth by 11% of the current distance from the
earth to the sun. No small task! The earth is in a circular orbit (or
close enough). To change to a circular orbit of larger radius requires
two applications of thrust at opposite points in the orbit It turns out
that the required boost in speed (the ratio of the speeds just before
and after applying thrust) for the first boost of an object changing
orbits is given by
&lt;mathjax&gt;$$\\frac{v\_{f}}{v\_{i}}=\\sqrt{\\frac{2R\_{f}}{R\_i+R\_f}}=1.026$$&lt;/mathjax&gt; To
move from the transfer orbit to the final circular orbit requires
&lt;mathjax&gt;$$\\frac{v\_{f}}{v\_{i}}=\\sqrt{\\frac{R\_{i}+R\_f}{2R\_i}}=1.027$$&lt;/mathjax&gt; Note
that despite the fact that we boost the velocity at both points, the
velocity of the final orbit is less than that of the initial. Now, how
could we apply that much thrust? Well, the change in momentum for the
earth from each stage is roughly (ignoring the slight velocity increase
of the transfer orbit) &lt;mathjax&gt;$$\\Delta p = .03M\_E v\_E $$&lt;/mathjax&gt; The mass of the
earth is \~6*10\^24 kg, the orbital velocity is \~30 km/s, so &lt;mathjax&gt;$$\\Delta
p = 5\\cdot 10\^{27} kg\*m/s$$&lt;/mathjax&gt; A solid rocket booster (the booster
rocket used for shuttle launches, when those still happened) can apply
about 12 &lt;span class="caps"&gt;MN&lt;/span&gt; of force for 75 s (thank you wikipedia). That&amp;#8217;s a net
momentum change of \~900 *10\^9 kg*m/s (900 billion!). So we would
only need &lt;mathjax&gt;$$\\frac{2\*5\\cdot 10\^{27}}{9\\cdot 10\^{11}}=12 \\cdot
10\^{15}$$&lt;/mathjax&gt; That&amp;#8217;s right, only 12 million billion booster rockets! With
those I can freeze the earth. I assure you that this plan is proceeding
on schedule, and will be ready shortly after we have constructed our
volcano&amp;nbsp;lair.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Earth Day 2012: Escape to the Moon</title><link href="/posts/earth-day-2012-escape-to-the-moon.html" rel="alternate"></link><updated>2012-04-22T15:12:00-04:00</updated><author><name>Brian</name></author><id>tag:,2012-04-22:posts/earth-day-2012-escape-to-the-moon.html</id><summary type="html">&lt;p&gt;It is now Earth Day 2012, and, according to the Mayan predictions, &lt;a href="http://thevirtuosi.blogspot.com/search/label/end%20of%20the%20earth"&gt;The
Virtuosi will destroy the
earth&lt;/a&gt;.
In a futile attempt to fight my own mortality, I decided to send
something to the Moon. It seems, for a poor graduate student trying to
get to the Moon, the most difficult part is the Earth holding me back.
So first I&amp;#8217;ll focus on escaping the Earth&amp;#8217;s gravitational potential
well, and if that&amp;#8217;s possible, then I&amp;#8217;ll worry about more technical
problems, such as actually hitting the moon. Moreover, in honor of the
destructive spirit of The Virtuosi near Earth Day, I&amp;#8217;ll try to do this
in the most Wiley-Coyote-esque way possible. &lt;strong&gt;Preliminaries&lt;/strong&gt; If we
want to get to the Moon, we need to first figure out how much energy
we&amp;#8217;ll need to escape the Earth&amp;#8217;s gravitational pull. &amp;#8220;That&amp;#8217;s easy!&amp;#8221; you
say. &amp;#8220;We need to escape a gravitational well, and we know from Newton&amp;#8217;s
law that the potential from a spherical mass &lt;em&gt;&lt;span class="caps"&gt;ME&lt;/span&gt;&lt;/em&gt; &amp;#8216;s gravity for a test
mass &lt;em&gt;m&lt;/em&gt; is : \begin{equation} \Phi = - \frac {G M_{E} m}{r}
\label{eqn:gravpot} \end{equation} We&amp;#8217;re currently sitting at the
radius of the Earth &lt;em&gt;&lt;span class="caps"&gt;RE&lt;/span&gt;&lt;/em&gt;, so we simply need to plug this value in and
we&amp;#8217;ll find out how much energy we need.&amp;#8221; This is all well and good, but
i) I can never remember what the gravitational constant &lt;em&gt;G&lt;/em&gt; is, and ii)
I have no idea what the mass of the Earth &lt;em&gt;&lt;span class="caps"&gt;ME&lt;/span&gt;&lt;/em&gt; is. So let&amp;#8217;s see if we
can recast this in a form that&amp;#8217;s easier to do mental arithmetic in.
Well, we know that the force of gravity is the related to the potential
by: &lt;mathjax&gt;$$ \\vec{F}(r) = - \\vec{\\nabla} \\Phi = - \\frac {d\\Phi}{dr}
\\hat{r} \\\\ \\vec{F} = - \\frac {G m M\_E } {r\^2}
\\label{eqn:gravforce} $$&lt;/mathjax&gt; Moreover, we all know that the force of
gravity at the Earth&amp;#8217;s surface is &lt;em&gt;F(r=&lt;span class="caps"&gt;RE&lt;/span&gt;)=-mg&lt;/em&gt;. Substituting this in
gives: &lt;mathjax&gt;$$ \\frac {G m M\_E} {R\_E\^2} = m g \\quad \\textrm{, or} $$&lt;/mathjax&gt;
\begin{equation} \frac {G m M_E}{R_E} = m g {R_E} \quad .
\label{eqn:betterDef} \end{equation} So the depth of the Earth&amp;#8217;s
potential well at the Earth&amp;#8217;s surface is &lt;em&gt;mgRE&lt;/em&gt;. If we use &lt;em&gt;g&lt;/em&gt; = 9.8
m/s\^2 \~ 10 m/s\^2 and &lt;em&gt;&lt;span class="caps"&gt;RE&lt;/span&gt;&lt;/em&gt; = 6378 km \~ 6x10\^6 m, then we can write
this as \begin{equation} \Delta \Phi = m g {R_E} \approx m \times
6 \times 10\^7 \textrm{m}\^2/\textrm{s}\^2 \quad \textrm{(1)},
\end{equation} give or take. How fast do we need to go if we&amp;#8217;re going
to make it to the Moon? Well, at the minimum, we need the kinetic energy
of our object to be equal to the depth of the potential well
&lt;a href="#footnote-1"&gt;[1]&lt;/a&gt;, or &lt;mathjax&gt;$$ \\frac 1 2 m v\^2 = 6 m \\times 10\^7
\\textrm{m}\^2/\\textrm{s}\^2 \\quad \\textrm{or} \\\\ v \\approx 1.1
\\times 10\^4 \\textrm{ m/s (2)} . $$&lt;/mathjax&gt; So we need to go pretty fast &amp;#8212;
this is about Mach 33 (33 times the speed of sound in air). At this
speed, we&amp;#8217;d get from &lt;span class="caps"&gt;NYC&lt;/span&gt; to &lt;span class="caps"&gt;LA&lt;/span&gt; in under 7 minutes. Looks difficult, but
let&amp;#8217;s see just how difficult it is. &lt;strong&gt;Attempt I: Shoot to the Moon&lt;/strong&gt;
What goes fast? Bullets go fast. Can we shoot our payload to the moon?
Let&amp;#8217;s make some quick estimates. First, can we shoot a regular bullet to
the moon? Well, we said that we need to go about Mach 33, and a fast
bullet only goes about Mach 2, so we won&amp;#8217;t even get close. Since energy
is proportional to velocity squared, we&amp;#8217;ll only have (2/33)\^2 \~ 0.4 %
of the necessary kinetic energy. &lt;a href="#footnote-2"&gt;[2]&lt;/a&gt; So let&amp;#8217;s make a
bigger bullet. How big does it need to be? Well, loosely speaking, we
have the chemical potential energy of the powder being converted into
kinetic energy of the bullet. Let&amp;#8217;s assume that the kinetic energy
transfer ratio of the powder is constant. If a bullet receives kinetic
energy &lt;em&gt;1/2mbvb\^2&lt;/em&gt; from a mass &lt;em&gt;mP&lt;/em&gt; of powder, then for our payload to
have kinetic energy &lt;em&gt;1/2 M V\^2&lt;/em&gt;, we need a mass of powder &lt;em&gt;&lt;span class="caps"&gt;MP&lt;/span&gt;&lt;/em&gt; such
that \begin{equation} \frac {M_P} {m_P} = \frac M {m_b} \times
\frac {V\^2}{v_b\^2} \end{equation} A quick reference to Wikipedia
for a &lt;a href="http://en.wikipedia.org/wiki/7.62%C3%9751mm_NATO"&gt;7.62x51mm &lt;span class="caps"&gt;NATO&lt;/span&gt;
bullet&lt;/a&gt; shows that
\~25 grams of powder propels a \~10 gram bullet at a speed of \~Mach
2.5. We need to get our payload moving at Mach 33, so (&lt;em&gt;V/vb&lt;/em&gt;)\^2 \~
175. If we send a 10 kg payload to the Moon, we have &lt;em&gt;M/mb&lt;/em&gt; \~ 1000. So
we&amp;#8217;ll need about 1.75 x 10\^5 the amount of powder of a bullet to get us
to the Moon, or about 4400 kg, which is 4.8 tons (English) of powder.
That&amp;#8217;s a lot of gunpowder to get us to the Moon. For comparison, if we
are going to construct a tube-like &amp;#8220;case&amp;#8221; for our 10 kg
bullet-to-the-Moon, it will have to be about half a meter in diameter
and 17 feet tall. So I&amp;#8217;m not going to be able to shoot anything to the
Moon anytime soon. &lt;strong&gt;Attempt &lt;span class="caps"&gt;II&lt;/span&gt;: Charge to the Moon&lt;/strong&gt; &lt;span class="caps"&gt;OK&lt;/span&gt;, shooting
something to the Moon is out. Can we use an electric field to propel
something to the Moon? Well, we would need to pass a charged object
through a potential difference such that \begin{equation} q \Delta
\Phi_E = m g R_E = 6 m \times 10\^7 \textrm{m}\^2/\textrm{s}\^2
\quad . \label{eqn:chargepot} \end{equation} After the humiliation of
the last section, let&amp;#8217;s start out small. Can we send an electron to the
Moon? We could plug numbers into this equation, but I&amp;#8217;m too lazy to look
up all those values. Instead, we know that we need to get our electron
(rest mass 511 keV) to a speed which is (Eq. 2) &lt;mathjax&gt;$$v \\approx 1.1 \\times
10\^4 \\textrm{m/s} \\approx 4 \\times 10\^{-5} c. $$&lt;/mathjax&gt; So an electron
moving at this velocity will have a kinetic energy of &lt;mathjax&gt;$$ \\textrm{KE} =
m c\^2 \\times \\frac 1 2 \\frac {v\^2}{c\^2} = 511 \\textrm{ keV}
\\times \\frac 1 2 \\frac {v\^2}{c\^2} \\\\ \\qquad \\approx 511
\\textrm{ keV} \\times 0.8 \\times 10\^{-9} \\approx 0.4 \\times
10\^{-3} eV. $$&lt;/mathjax&gt; So we can give an electron enough kinetic energy to get
to the moon with a voltage difference of 0.4 mV, assuming it doesn&amp;#8217;t hit
anything on the way up (it will). We can send an electron to the Moon!
How about a proton? Well, the mass of a proton is 1836x that of an
electron, but with the same charge, so we&amp;#8217;d need 1836 * 0.4 mV \~ 0.73
V to get a proton to the Moon &amp;#8212; again, pretty easy. Continuing this
logic, we can send a singly-charged ion with mass 12 amu (&lt;em&gt;i.e.&lt;/em&gt; C-)
with a 9V battery, and a singly-charged ion with mass 150 amu (something
like caprylic acid) using a 110V voltage drop. (Again, assuming these
don&amp;#8217;t hit anything on the way up.) How about our 10 kg object? Let&amp;#8217;s say
we can miraculously charge it with 0.01 C of charge. &lt;a href="#footnote-3"&gt;[3]&lt;/a&gt;
Then from Eq. (1), we&amp;#8217;d need &lt;mathjax&gt;$$ 0.01 C \\times \\Delta \\Phi\_E \\approx
6 \\times 10\^8 \\textrm{ J ,} $$&lt;/mathjax&gt; or a potential difference of &lt;mathjax&gt;$$
\\Delta \\Phi\_E = 6 \\times 10\^{10} \\textrm{ V. } $$&lt;/mathjax&gt; That is a &lt;span class="caps"&gt;HUGE&lt;/span&gt;
potential drop. For comparison, if we have 2 parallel plates with a
surface charge of 0.01 C/m\^2 (again, a huge charge density), they&amp;#8217;d
have to be a distance &lt;mathjax&gt;$$ d = 6 \\times 10\^{10} \\textrm{V} \\times
\\epsilon\_0 / (0.01 \\textrm{C/m}\^2) \\approx 53 \\textrm{ meters
apart} $$&lt;/mathjax&gt; It looks like I won&amp;#8217;t be able to send something to the Moon
using tools from my basement anytime soon.
[1] We&amp;#8217;ll ignore both air resistance and the Moon&amp;#8217;s gravitational
attraction for simplicity.
[2] Since the potential &lt;em&gt;U \~ - 1/r&lt;/em&gt;, if we increase our potential
energy by 0.4%, this is (to 1st order) the same as increasing &lt;em&gt;r&lt;/em&gt; by
0.4%. So we&amp;#8217;ll get 0.004 * 6378 km \~ 25 km above the Earth&amp;#8217;s surface.
Of course &lt;a href="http://scienceblogs.com/dotphysics/2009/09/how-high-does-a-bullet-go.php"&gt;air resistance slows it down a
lot&lt;/a&gt;.
[3] According to Wikipedia, this is &lt;a href="http://en.wikipedia.org/wiki/Orders_of_magnitude_%28charge%29"&gt;0.04% of the total charge of a
thundercloud&lt;/a&gt;.
And if our object is uniformly charged with a radius of 1 m, it will
have an electrical self-energy of ** &lt;mathjax&gt;$$ U = \\frac 1 2 \\int
\\epsilon\_0 E\^2 dV \\approx 36 \\textrm{kJ} $$&lt;/mathjax&gt;&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Calculator Pi</title><link href="/posts/calculator-pi.html" rel="alternate"></link><updated>2012-03-14T14:16:00-04:00</updated><author><name>Alemi</name></author><id>tag:,2012-03-14:posts/calculator-pi.html</id><summary type="html">&lt;p&gt;There is a very fast converging algorithm for computing pi that you can
do on a desktop&amp;nbsp;calculator.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set x =&amp;nbsp;3&lt;/li&gt;
&lt;li&gt;Now set x = x +&amp;nbsp;sin(x)&lt;/li&gt;
&lt;li&gt;Repeat&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This converges ridiculously fast, after 1 step you get 4 digits right,
after 2 steps you get 11 correct, in general we&amp;nbsp;find:&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;# steps   Digits right
  1          4
  2          11
  3          33
  4          100
  5          301
  6          903
  7          2708
  8&amp;nbsp;8124&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;of course on a pocket calculator, you only need to do 2 steps to have an
accuracy greater than the calculator can display. To make this chart I
had to trick a computer into doing high precision arithmetic, the code
is &lt;a href="https://gist.github.com/2038329"&gt;here&lt;/a&gt;. Granted, this approximation
is really cheating, since sin is a hard function to compute, and
basically being able to compute sin means you know what pi is already.
Really, this is just &lt;a href="http://en.wikipedia.org/wiki/Newton's_method"&gt;Newton&amp;#8217;s
method&lt;/a&gt; for computing the
root of sin(x) in&amp;nbsp;disguise&lt;/p&gt;</summary><category term=""></category></entry><entry><title>The Stars Fell on Abe and Frederick</title><link href="/posts/the-stars-fell-on-abe-and-frederick.html" rel="alternate"></link><updated>2012-01-02T20:02:00-05:00</updated><author><name>Corky</name></author><id>tag:,2012-01-02:posts/the-stars-fell-on-abe-and-frederick.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;&lt;a href="http://3.bp.blogspot.com/-p3-DTUn3sJ0/TwJnlct7XLI/AAAAAAAAASQ/1nZ0xtbwXHo/s1600/leonids_pic.jpg"&gt;&lt;img alt="image" src="http://3.bp.blogspot.com/-p3-DTUn3sJ0/TwJnlct7XLI/AAAAAAAAASQ/1nZ0xtbwXHo/s320/leonids_pic.jpg" /&gt;&lt;/a&gt;
  The 1833 Leonids (Source:&amp;nbsp;Wikipedia)&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Word on the street is there&amp;#8217;s a meteor shower set for late Tuesday
night, peaking at 2 am &lt;span class="caps"&gt;EST&lt;/span&gt; on January 4th &lt;a href="#footnote-1"&gt;[1]&lt;/a&gt;&lt;a href=""&gt;&lt;/a&gt;. The
meteors in question are the
&lt;a href="http://en.wikipedia.org/wiki/Quadrantids"&gt;Quadrantids&lt;/a&gt;, which often go
unnoticed for two good reasons. Reason the first: apparently
&lt;a href="#footnote-2"&gt;[2]&lt;/a&gt;&lt;a href=""&gt;&lt;/a&gt;, they are usually pretty awful. Unlike the &amp;#8220;good&amp;#8221;
meteor showers, the Quadrantids are bright and pretty for only a few
hours (instead of a few days). This means that a lot of the time, we
just miss them. Reason the second: they have a lame name
&lt;a href="#footnote-3"&gt;[3]&lt;/a&gt;&lt;a href=""&gt;&lt;/a&gt;. But this year, they should be pretty good if the
weather is right. Now, there&amp;#8217;s lots of neat physics to talk about with
meteors, but that&amp;#8217;s not why I bring it up. This has all just been flimsy
pretext so I could share a historical anecdote about a meteor shower.
Trickery, indeed. Those who feel cheated are free to leave now with
&lt;a href="http://www.youtube.com/watch?v=apu_585SW18"&gt;heads held high&lt;/a&gt;. Those
still around (Hi, Mom!) will hear about the night in 1833 when the stars
fell on &lt;a href="http://www.youtube.com/watch?v=6ibV3tCDvd8"&gt;Alabama&lt;/a&gt; (and the
rest of the country, too). The
&lt;a href="http://en.wikipedia.org/wiki/Leonids"&gt;Leonids&lt;/a&gt; typically put on a
pretty good show, but their showing in 1833 was so dramatic that the
term &amp;#8220;meteor shower&amp;#8221; was coined to describe what was happening. The 1833
Leonids were truly one for the ages and made such an impression that
people were often able to remember when events happened by their
relation to the night when &amp;#8220;the stars fell.&amp;#8221; It was in this use as a
&amp;#8220;calendar anchor&amp;#8221; that I first heard of this particular meteor shower.
While home for the holiday I was reading &lt;em&gt;Life and Times of Frederick
Douglass&lt;/em&gt;, one of the later autobiographies written by the former slave
and noted abolitionist. Recounting when he was moved from Baltimore to a
plantation on the Eastern Shore of Maryland, Douglass&amp;nbsp;writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I went to St. Michaels to live in March, 1833. I know the year,
because it was the one succeeding the first cholera in Baltimore, and
was also the year of that strange phenomenon when the heavens seemed
about to part with their starry train. I witnessed this gorgeous
spectacle, and was awe-struck. The air seemed filled with bright
descending messengers from the sky. It was about daybreak when I saw
this sublime scene. I was not without the suggestion, at the moment,
that it might be the harbinger of the coming of the Son of Man; and in
my then state of mind I was prepared to hail Him as my friend and
deliverer. I had read that the &amp;#8220;stars shall fall from heaven,&amp;#8221; and
they were now falling. I was suffering very much in my mind. It did
seem that every time the young tendrils of my affection became
attached they were rudely broken by some unnatural outside power; and
I was looking away to heaven for the rest denied me on&amp;nbsp;earth.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Douglass wrote these words almost 50 years after the fact and it is
evident that the meteor shower clearly had an effect on him. By this
time (at age 15), Douglass had already made up his mind to escape from
slavery. Three years later, he made a failed attempt. Two years after
that, in 1838, Frederick Douglass escaped to the North and became an
influential abolitionist. After reading the above passage from Douglass,
I wondered who else may have seen the 1833 Leonids. After a bit of
research, I found a paper by &lt;a href="http://ecommons.txstate.edu/cgi/viewcontent.cgi?article=1004&amp;amp;context=physfacp&amp;amp;sei-redir=1&amp;amp;referer=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3Dolson%2Blincoln%2Bleonids%26source%3Dweb%26cd%3D1%26ved%3D0CB4QFjAA%26url%3Dhttp%253A%252F%252Fecommons.txstate.edu%252Fcgi%252Fviewcontent.cgi%253Farticle%253D1004%2526context%253Dphysfacp%26ei%3DaogCT_2TB4rv0gGZ_5HoBw%26usg%3DAFQjCNE8HE4-k_Zcl2PzK2shdtMCi6ZyEQ#search=%22olson%20lincoln%20leonids%22"&gt;Olson &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Jasinski
(1999)&lt;/a&gt;
which provides an excerpt from Walt Whitman recounting a story told by
Abraham Lincoln. Whitman&amp;nbsp;writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the gloomiest period of the war, he [Lincoln] had a call from a
large delegation of bank presidents. In the talk after business was
settled, one of the big Dons asked Mr. Lincoln if his conﬁdence in the
permanency of the Union was not beginning to be shaken — whereupon the
homely President told a little story. “When I was a young man in
Illinois,” said he, “I boarded for a time with a Deacon of the
Presbyterian church. One night I was roused from my sleep by a rap at
the door, &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; I heard the Deacon’s voice exclaiming ‘Arise, Abraham, the
day of judgment has come!’ I sprang from my bed &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; rushed to the
window, and saw the stars falling in great showers! But looking back
of them in the heavens I saw all the grand old constellations with
which I was so well acquainted, ﬁxed and true in their places.
Gentlemen, the world did not come to an end then, nor will the Union&amp;nbsp;now.&amp;#8221;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Abraham Lincoln witnessed the 1833 meteor shower and was still telling
stories about it 30 years&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;So what&amp;#8217;s the point of this whole story? Is there any significance to
the fact that the man who escaped slavery to tell the world of its evils
and &amp;#8220;The Great Emancipator&amp;#8221; both saw the same meteor shower? Probably
not. Tons of people saw&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Regardless, it is interesting to think about. Though these men would
cross paths several times over the next 30 years, the earliest memory
they shared was of a night in 1833, when a 15 year old slave in Maryland
and a 24 year old boarder in Illinois watched the stars fall from the&amp;nbsp;sky.&lt;/p&gt;
&lt;p&gt;[1] I use &amp;#8220;Tuesday night&amp;#8221; here to mean, of course, &amp;#8220;Wednesday morning.&amp;#8221;
&lt;a href="#back-1"&gt;[back]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] I say &amp;#8220;apparently&amp;#8221; because I have never heard of these guys before,
so this is all Wikipedia, baby! &lt;a href="#back-2"&gt;[back]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] Like other meteor showers, the Quadrantids take their name from the
constellation from which the meteors seem to emerge. In this case,
&lt;a href="http://en.wikipedia.org/wiki/Quadrans_Muralis"&gt;Quadrans Mural&lt;/a&gt;: The
Mural Quadrant. Unfortunately for Quadrans Mural, the constellations
dumped it like the planets dumped Pluto. &lt;a href="#back-3"&gt;[back]&lt;/a&gt;&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Earth Day Special: Post-Apocalyptic Literature</title><link href="/posts/earth-day-special-post-apocalyptic-literature.html" rel="alternate"></link><updated>2011-04-22T10:30:00-04:00</updated><author><name>Alex</name></author><id>tag:,2011-04-22:posts/earth-day-special-post-apocalyptic-literature.html</id><summary type="html">&lt;p&gt;&lt;a href="http://upload.wikimedia.org/wikipedia/en/2/23/Emergence_cover_first_edition.jpg"&gt;&lt;img alt="image" src="http://upload.wikimedia.org/wikipedia/en/2/23/Emergence_cover_first_edition.jpg" /&gt;&lt;/a&gt;
At some point in elementary school I got into the habit of reading Franz
Kafka&amp;#8217;s &lt;a href="http://en.wikipedia.org/wiki/The_Metamorphosis"&gt;The
Metamorphosis&lt;/a&gt; every
time that I got sick. I found it strangely comforting to be reminded
that while I might have &lt;a href="http://en.wikipedia.org/wiki/Scarlet_fever"&gt;scarlet
fever&lt;/a&gt; and be intermittently
hallucinating about Mickey Mouse, at least I had not been (spoiler
alert!) turned into a giant cockroach and disowned by my family. Today
is &lt;a href="http://www.google.com/webhp?hl=en#q=Earth+Day&amp;amp;bav=on.2,or.r_gc.r_pw.&amp;amp;fp=38378e84586d88e6"&gt;Earth
Day&lt;/a&gt;!
The earth has seen better days, and I got too depressed googling various
environmental problems to even come up with a suitable list of examples.
However, look on the &lt;a href="http://www.youtube.com/watch?v=WlBiLNN1NhQ"&gt;bright
side&lt;/a&gt;: things could be much,
much worse. To explore how much worse it could be, here&amp;#8217;s a few of my
favorite works of post-apocalyptic fiction - perfect reading for Earth
Day. Skip past the cut to check them out. In no particular order, here&amp;#8217;s
some of my favorite post-apocalyptic fiction. Many of these are aimed
more toward young adults, and since this is a science blog, I&amp;#8217;ve also
tried to score them arbitrarily on their scientific plausibility (0-10).
Check out the associated amazon pages for better descriptions and&amp;nbsp;reviews.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Z-Zachariah-Robert-C-OBrien/dp/0020446500"&gt;Z for
    Zachariah&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Robert C. O&amp;#8217;Brien - Where&amp;#8217;s the best place to be when a nuclear
war goes down? In a isolated valley in upstate New York, apparently!
Z for Zachariah follows a 16 year old girl who is left to fend for
herself after the bombs go off, until a Cornell chemistry postdoc
shows up in a radiation suit.&amp;nbsp;7/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Postman-Bantam-Classics-David-Brin/dp/0553278746/ref=pd_sim_b_3"&gt;The
    Postman&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;David Brin - Another in the post-nuclear war sub-genre. The story
gets bogged down in weird survivalist themes in the second half, but
paints a rather believable portrait of the aftermath of a nuclear
winter.&amp;nbsp;5/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Canticle-Leibowitz-Walter-Miller-Jr/dp/0060892994/ref=pd_sim_b_5"&gt;A Canticle for
    Liebowitz&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Walter Miller - Have you ever been stuck in a waiting room at the
dentist&amp;#8217;s and the only thing to read is a Reader&amp;#8217;s Digest from 1983?
In the future, it&amp;#8217;s like that, only way worse.&amp;nbsp;6/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Childhoods-End-Del-Rey-Impact/dp/0345444051/ref=pd_sim_b_5"&gt;Childhood&amp;#8217;s
    End&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Aurthur C. Clark - Sometimes the end of the world is surprisingly
zen.&amp;nbsp;3/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Gift-Upon-Shore-M-Wren/dp/0595143415/ref=sr_1_1?ie=UTF8&amp;amp;s=books&amp;amp;qid=1303485614&amp;amp;sr=1-1"&gt;A Gift Upon the
    Shore&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;span class="caps"&gt;M. K.&lt;/span&gt; Wren - Rural Oregon also turns out to be a decent place to
ride out a nuclear winter. Everything is great, unless your only
surviving neighbors are fundamentalists.&amp;nbsp;7/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Emergence-David-R-Palmer/dp/B002U4W1QA/ref=sr_1_8?s=books&amp;amp;ie=UTF8&amp;amp;qid=1303485800&amp;amp;sr=1-8"&gt;Emergence&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;David R. Palmer - This is probably my favorite work in this genre.
Emergence is the diary of a very plucky Candidia Smith-Foster, who,
along with a pet parrot, has survived a communist bio attack. Things
get a bit nutty in the end, but overall a very enjoyable read.
Despite great reviews it&amp;#8217;s currently out of print, although a movie
may be in the works.&amp;nbsp;8/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://listverse.com/2009/02/12/10-great-post-apocalyptic-science-fiction-novels/"&gt;I am
    Legend&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;It turns out that Will Smith was actually playing an older white
dude. Who knew? It shares strange religious overtones with the
movie, but much better written and with a totally different ending.&amp;nbsp;4/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Pesthouse-Vintage-Jim-Crace/dp/0307278956/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1303487441&amp;amp;sr=1-1"&gt;The
    Pesthouse&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Jim Crace - Society has gone a long way backwards, but they hear
everything is better in Europe.&amp;nbsp;5/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Road-Movie-Tie--Vintage-International/dp/0307476316/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1303487550&amp;amp;sr=1-1"&gt;The
    Road&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Cormac McCarthy - I can&amp;#8217;t say I&amp;#8217;m a huge fan of his writing style,
but the world that Cormac McCarthy creates here is very compelling,
although mind-numbingly depressing.&amp;nbsp;9/10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is by no means an exhaustive list - there&amp;#8217;s a lot of classics that
I haven&amp;#8217;t gotten around to reading yet such as &lt;a href="http://www.amazon.com/Beach-Vintage-International-Nevil-Shute/dp/0307473996/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1303487212&amp;amp;sr=1-1"&gt;On the
Beach.&lt;/a&gt;
I also have high hopes for Kim Stanley Robinson&amp;#8217;s &lt;a href="http://www.amazon.com/gp/product/0312890362?ie=UTF8&amp;amp;tag=jamifrat-20&amp;amp;linkCode=as2&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0312890362"&gt;The Wild
Shore&lt;/a&gt;
since I enjoyed his Mars series. Anyone else have anything to add? Happy
Earth&amp;nbsp;Day!&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Exploration of Cameras I</title><link href="/posts/exploration-of-cameras-i.html" rel="alternate"></link><updated>2011-02-03T19:50:00-05:00</updated><author><name>Matt</name></author><id>tag:,2011-02-03:posts/exploration-of-cameras-i.html</id><summary type="html">&lt;p&gt;In the next posts, I&amp;#8217;d like to attempt to make a camera from &amp;#8216;scratch.&amp;#8217;
And by that, I mean explore the creation of cameras from their
components and then create a very primitive one from readily available&amp;nbsp;materials.&lt;/p&gt;
&lt;p&gt;In terms of history and simplicity, we should start with the pinhole
camera. I&amp;#8217;ve heard stories that Newton used a pinhole camera to look at
the sun though I don&amp;#8217;t know if this was before or after he stared
directly at it for 8 minutes. The pinhole is neat because it is so
simple. With a pinhole, light is focused simply by restricting the paths
which an incident ray may take to hit our film. Typically, diffuse and
specular scattering sends light bouncing every which way off an object.
The pinhole just restricts which directions hit the film. I think a
picture is a better guide to this&amp;nbsp;concept.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://4.bp.blogspot.com/_qY9DSyjj8Ro/TUtOYzRfZAI/AAAAAAAAB3Y/MoKfumAjRTs/s400/pinholes2.png" /&gt;&lt;/p&gt;
&lt;p&gt;For a small hole (aperture) there is approximately one area of the
object that will send rays to a particular part of the image. Of course
there is a very small angle of error for pinhole cameras made with
millimeter sized pins. As the hole increases in size, more rays are
incident to the same section of film. And finally, when the hole is big
enough for the whole object to be seen through it (think window), no
cohesive image is&amp;nbsp;formed.&lt;/p&gt;
&lt;p&gt;So if we make the hole small enough, then we can have all the clarity we
want, right? Well, I guess so. It would have to be a very circular hole
and it would only let in a very tiny amount of light making exposure
times long. How to fix&amp;nbsp;this?&lt;/p&gt;
&lt;p&gt;Yea, you guessed it. A lens is the answer. It is able to focus light on
its own. Now we can collect more light and still make clear images. But
the catch is that it only works for a range of distances. So again, lets
consider a lens and the images of two objects at different&amp;nbsp;distances.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://3.bp.blogspot.com/_qY9DSyjj8Ro/TUtO6Js1a6I/AAAAAAAAB3g/6s0Nh2XYoFY/s1600/lenses2.png"&gt;&lt;img alt="image" src="http://3.bp.blogspot.com/_qY9DSyjj8Ro/TUtO6Js1a6I/AAAAAAAAB3g/6s0Nh2XYoFY/s400/lenses2.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ray drawing can be done with 3 simple rules (though two are needed in&amp;nbsp;practice).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rays that go in parallel to the axis go out through the focal&amp;nbsp;point&lt;/li&gt;
&lt;li&gt;rays that go in through the focal point go out parallel (time
    reversal&amp;nbsp;symmetry)&lt;/li&gt;
&lt;li&gt;rays that go through the center are not&amp;nbsp;altered&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using these rules, the first object which is at the proper distance for
the film position and focal length of the lens is in focus. However, the
rays from the object further away do not converge at the film and so are
out of&amp;nbsp;focus.&lt;/p&gt;
&lt;p&gt;Here its time for two&amp;nbsp;experiments.&lt;/p&gt;
&lt;p&gt;\1) &lt;strong&gt;The Window Camera&lt;/strong&gt; Go to a room with a single window and cover it
with thick paper that has a single hole in it. Given enough light, you
should see an image on the far wall. If not, hold a piece of white paper
up close to the hole. [Edit: I just learned this has a name: &lt;a href="http://en.wikipedia.org/wiki/Camera_obscura"&gt;camera
obscura&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;\2) &lt;strong&gt;The Doorway Camera&lt;/strong&gt; Now, find a lens and a doorway. In one room,
leave the light on and go to the far wall in the dark room. Bring the
lens to the wall until you can see an image. The doorway is the
aperature, lens the lens, and wall the film. This demonstration is very
simple and not too surprising. &lt;span class="caps"&gt;BUT&lt;/span&gt; &lt;span class="caps"&gt;SO&lt;/span&gt; &lt;span class="caps"&gt;COOL&lt;/span&gt;. I encourage it &lt;em&gt;vigorously&lt;/em&gt;.
The following pictures were taken of my images in case you can&amp;#8217;t find a
lens. [Edit: I guess this falls under camera obscura&amp;nbsp;too]&lt;/p&gt;
&lt;p&gt;&lt;a href="http://4.bp.blogspot.com/_qY9DSyjj8Ro/TUtR0FcieuI/AAAAAAAAB3o/AETwbMrWO_A/s1600/bailey-real.JPG"&gt;&lt;img alt="image" src="http://4.bp.blogspot.com/_qY9DSyjj8Ro/TUtR0FcieuI/AAAAAAAAB3o/AETwbMrWO_A/s400/bailey-real.JPG" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bailey Hall through a window in the physics&amp;nbsp;building.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/_qY9DSyjj8Ro/TUtSCaBSQZI/AAAAAAAAB3w/YePJ9Jy-Qj0/s1600/bailey-lens.JPG"&gt;&lt;img alt="image" src="http://1.bp.blogspot.com/_qY9DSyjj8Ro/TUtSCaBSQZI/AAAAAAAAB3w/YePJ9Jy-Qj0/s400/bailey-lens.JPG" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Same scene as imaged with a lens using the window as an&amp;nbsp;aperture.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://1.bp.blogspot.com/_qY9DSyjj8Ro/TUtS-MYX9RI/AAAAAAAAB34/VSLnyE4Gbs8/s1600/light%2Bfixture.jpg"&gt;&lt;img alt="image" src="http://1.bp.blogspot.com/_qY9DSyjj8Ro/TUtS-MYX9RI/AAAAAAAAB34/VSLnyE4Gbs8/s320/light%2Bfixture.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Image of a ceiling light with a smaller&amp;nbsp;lens&lt;/p&gt;
&lt;p&gt;&lt;a href="http://4.bp.blogspot.com/_qY9DSyjj8Ro/TUtTSBzC1LI/AAAAAAAAB4A/W6xD0OEykkk/s1600/psb.JPG"&gt;&lt;img alt="image" src="http://4.bp.blogspot.com/_qY9DSyjj8Ro/TUtTSBzC1LI/AAAAAAAAB4A/W6xD0OEykkk/s320/psb.JPG" /&gt;&lt;/a&gt;Physical
Sciences Building imaged on&amp;nbsp;wood.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://3.bp.blogspot.com/_qY9DSyjj8Ro/TUtTqmUzTPI/AAAAAAAAB4I/rDMMFj5AsJE/s1600/small.jpg"&gt;&lt;img alt="image" src="http://3.bp.blogspot.com/_qY9DSyjj8Ro/TUtTqmUzTPI/AAAAAAAAB4I/rDMMFj5AsJE/s320/small.jpg" /&gt;&lt;/a&gt;An
extra small image (\~1cm on a side) from the lens that will be in next
post&amp;#8217;s&amp;nbsp;camera.&lt;/p&gt;
&lt;p&gt;Together, these two elements – aperture and lens – make a very good
camera. The lens is able to collect a lot of light and focus it on the
film. The aperture can enhance clarity by reducing the number of paths
that light rays can take to your lens. It also provides higher order
corrections that come from the fact that the lens is probably not
perfect. That is, lenses are notorious for misbehaving around the edges
and introduce displacements in the whole image as well as between the
colors. The aperture helps keep light from traveling through these&amp;nbsp;edges.&lt;/p&gt;
&lt;p&gt;Next time, a very simple&amp;nbsp;camera.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Your Week in Seminars: Short Thanksgiving edition</title><link href="/posts/your-week-in-seminars-short-thanksgiving-edition.html" rel="alternate"></link><updated>2010-11-29T18:51:00-05:00</updated><author><name>Yariv</name></author><id>tag:,2010-11-29:posts/your-week-in-seminars-short-thanksgiving-edition.html</id><summary type="html">&lt;p&gt;Good Monday evening all, and welcome to another edition of Your Week in
Seminars. Last week was a half week here in Cornell, but we still
managed two talks, the general colloquium and the
Wednseday-talk-on-Tuesday. Monday we had Charles Marcus of Harvard talk
about Building Schrödinger&amp;#8217;s Chip. This was a quantum computing talk. We
don&amp;#8217;t actually have a quantum computing group in Cornell, but I&amp;#8217;ve taken
a couple of courses on it back home, and it&amp;#8217;s an interesting subject,
although I&amp;#8217;ve been a bit disillusion by the notable lack of problems
solvable by quantum computers. Marcus started by talking about the
wonders and insanities of quantum mechanics - the usual spiel about the
two slit experiment, electrons passing through walls, and Schrödinger&amp;#8217;s
cat. He said he dubbed the talk Schrödinger&amp;#8217;s chip because unlike cats,
that appear to break when we put them in the kind of low-temperature
vacuum conditions we like to do quantum experiments in, chips keep
working pretty well. Next he introduced the concept of entanglement,
which is at the basis of the whole concept of quantum computing.
Entangled particles are two or more particles that do not have a
definite quantum state, but are definitely in the same quantum state. If
I take them apart and measure their state - say, spin up or down - then
I do not know the answer, but as soon one turns up, the other is up as
well, and if one is down the other is immediately down as well. The
experimental side of quantum computing is all about making little
quantum boxes that contain a small number of states (like up or down)
and then making it possible to entangle two of those boxes together. Add
up enough boxes, under some criteria that were posited a decade ago but
still not achieved, and you have a quantum computer. The majority of the
talk was a survey of the various state of the art boxes and the methods
used to make them. For those keeping track, 15 is still the largest
number factored by a quantum computer. On Tuesday, I came in just in
time for the second half of John Terning&amp;#8217;s talk on Monopoles, Anomalies,
and Electroweak Symmetry Breaking. It&amp;#8217;s not really ideal to go into the
second half of a talk in Newman 311, and this one actually sounded like
I missed some interesting stuff. The part that I heard was about adding
magnetic monopoles to the standard model., Those lovely magnetic
equivalents of the electric point charge that we all heard about in our
undergraduate E&amp;amp;M course turn out to be surprisingly hard to integrate
into basic particle theories, which is perhaps for the best as we have
not detected them so far. The gist of what I got from the second half of
the talk was that it is not enough to add a magnetic counterpart to the
electric part of the standard model, but in fact one needs a magnetic
&lt;span class="caps"&gt;QCD&lt;/span&gt; and Weak force as well. Under some conditions, this kind of
configuration can work, and predict magnetic monopoles with TeV-scale
masses - the kind we might see in the &lt;span class="caps"&gt;LHC&lt;/span&gt;. Terning also talked about how
these could be detected in the &lt;span class="caps"&gt;LHC&lt;/span&gt;. It turns out this isn&amp;#8217;t simple,
because at TeV we would be producing monopole-anti-monopole pairs just
barely, and so without a lot of kinetic energy they would tend to
collapse back on themselves and annihilate, creating what is essentially
an omnidirectional shower of photons. He mentioned that one of the big
detectors at the &lt;span class="caps"&gt;LHC&lt;/span&gt; - the &lt;span class="caps"&gt;CMS&lt;/span&gt; - was equipped to detect these kind of
photon bursts, and so this another prediction or possibility that we can
look forward to seeing or not seeing soon. That&amp;#8217;s it for last week, kind
of on the short side due to the holiday and so on. This week is our last
normal one, as the semester ends, but I&amp;#8217;ll have a couple more particle
talks the week after that, as&amp;nbsp;well.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Your Week in Seminars: One for Two Edition</title><link href="/posts/your-week-in-seminars-one-for-two-edition.html" rel="alternate"></link><updated>2010-11-22T11:12:00-05:00</updated><author><name>Yariv</name></author><id>tag:,2010-11-22:posts/your-week-in-seminars-one-for-two-edition.html</id><summary type="html">&lt;p&gt;Hello everyone and welcome to another week of talks here at the physics
department. I was out of Ithaca for a bit this past week, so in this
very special edition I&amp;#8217;m going to present a full week&amp;#8217;s worth of
seminars (one from last week and two from the previous week) in one post
covering two weeks. The Colloquium two weeks ago was given by our own
Csaba Csaki, who talked about Electroweak Symmetry Breaking and the
Physics of the TeV Scale. This was essentially an overview of
beyond-the-standard-model physics and the kind of things we expect out
of the &lt;span class="caps"&gt;LHC&lt;/span&gt;. Csaba started off by reminding us of the Standard Model, our
very successful model of particle physics that&amp;#8217;s withstood nearly every
test over the last thirty or forty years. The Standard Model is a set of
three gauge theories - three forces that a relayed by massless particles
- along with the theory of electroweak symmetry breaking that explains
why one of these powers, the Weak one, is relayed by massive particles.
This theory is well-backed by experiment, with the exception of the
crucial Higgs boson, the one that gives mass to those previously
massless W and Z, which we hope to see soon in the &lt;span class="caps"&gt;LHC&lt;/span&gt;. There are a few
problems with the Standard Model, and the big one is the Hierarchy
problem. Given what we know of symmetry breaking and how the W and Z get
their masses, we expect elementary particles to have masses that
correlate with the energy scale of the interaction that gives them this
mass. Since that interaction is not one we see at low energies, we
expect the elementary particles to be very massive. Since they are not,
we conclude that there must be some symmetry that keeps them massless or
nearly so. Some solutions to this was mentioned, beginning with
current-favorite supersymmetry. This extra symmetry relation bosons to
fermions and vice versa works well to solve the original problem, but
creates a few of its own, like the Little Hierarchy Problem - if there&amp;#8217;s
all this new physics at energies just a little higher than we&amp;#8217;ve been
exploring, why don&amp;#8217;t we see its effects on the low energy physics? In
other words, why does the non-sypersymmetry Standard Model work so well?
Csaba went on to mention some ways of solving these problems, such as
burying the Higgs by allowing it to decay only in very specific ways. He
also talked about a few more, like no-Higgs theories that accomplish
electroweak symmetry breaking by different means, and extra-dimensional
theories that allow us to give different energy scales to different
forces. And the exciting thing about all of this is that we are likely
to know a great deal of the answers soon, within the next few years,
once the &lt;span class="caps"&gt;LHC&lt;/span&gt; starts giving data. On Wednesday after it we had Sven
Krippendorf from Cambridge talk about Particle Physics from local
D-brane models at toric singularities. This was a heavy string theory
talk and I couldn&amp;#8217;t follow much of it. The question at hand was how to
get the Standard Model, or parts of it, out of string theory models, and
the gist of the talk revolved around toric singularities in the
spacetime that the string theory lives in. No, I&amp;#8217;m not entirely sure
what makes a singularity toric. There were a lot of colorful graphs and
some explanations. At the end there seemed to be some analogy made
between different types of singularities on the manifold in string
theory language and different gauge theories in the quantum field theory
language, with a way to map them to each other. Possibly exciting, but
you&amp;#8217;d have to ask a proper string theorist about it. Then just this last
Friday, we had Rachel Rosen from Stockholm University talk about Phase
Transitions of Charged Scalars and White Dwarf Stars. This was a
blackboard talk, which is always exciting and is usually more
illustrative than Power Point ones. The subject was the thermodynamics
of white dwarf stars - stars that are very dense and old, where fusion
has mostly stopped and the only thing preventing the collapse of the
star upon itself is the fermionic pressure of the electrons, that cannot
fall into the same quantum states. The physical description of these
stars is one of relatively free positive ions, specifically helium ions
in this case, floating through a background of fermions. They are
described by a quantum condensate, which has a good theory explaining
it, but with the addition of Coulombic interaction between the ions.
This state applies, specifically, to a subgroup of these stars that are
mostly made of helium. This kind of ion condensate tends to crystallize
depending on the ratio between the kinetic and potential Coulombic
energy. Quantum effects, on the other hand, depend on some ratios of
mass and charge between the ions. The only material where this applies
turns to be helium, but luckily there are plenty of these helium-made
white dwarfs. The derivation, as Rosen showed it, starts with a neutral
Bose-Einstein condensate, which has a simple phase diagram - uncondensed
above some critical temperature, and increasing condensation as the
temperature is lowered to zero. The charged condensate introduces
photons as it is usually done in field theory and follows the
consequences. The result is a more complicated phase diagram. Under the
old Tc, the ions still condense, but things change above it. There is
now some higher temperature above which there is no condensation, but in
between there are two solutions to the equations of motions, a
condensate and a non-condensed state, and both a local energy minima.
This means that the transition into a condensate is not continuous, and
this is a first order phase transition. The nice thing here is that we
have such white dwarf stars to observe and we can compare this theory to
observations. That&amp;#8217;s it for these last two weeks. All you Americans out
there have a good Thanksgiving, and I&amp;#8217;ll see you next week with two new&amp;nbsp;seminars.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Your Week in Seminars Dark Edition</title><link href="/posts/your-week-in-seminars-dark-edition.html" rel="alternate"></link><updated>2010-11-08T15:46:00-05:00</updated><author><name>Yariv</name></author><id>tag:,2010-11-08:posts/your-week-in-seminars-dark-edition.html</id><summary type="html">&lt;p&gt;Good afternoon everyone, and welcome to another week of seminars here in
the physics department. Our theme of the week is dark matter - where
does it come from, how do we see it, and why is there so much of it.
Along with that we have a little more AdS/&lt;span class="caps"&gt;CFT&lt;/span&gt;, seemingly continuing last
week&amp;#8217;s subjects theme. All in all, it looks like seminars on similar
subjects tend to condense here in the department. We start with the
Monday Colloquium, where Richard Schnee from Syracuse University told us
about What&amp;#8217;s the Matter in the Universe? Direct Searches for &lt;span class="caps"&gt;WIMP&lt;/span&gt; Dark
Matter. Dark matter, we&amp;#8217;ll recall, is the astrophysics name for any kind
of matter that doesn&amp;#8217;t emit light - one that is not inside stars. Our
knowledge of our own solar system, which has its mass concentrated
almost entirely inside the sun, led us to expect that mass in the
universe in general would behave similarly. It turns out that the motion
of observed galaxies is not consistent with the mass we measure them to
have, and so we hypothesize the existence of non-luminary matter around
us. These days dark matter is an object of interest not only for
astrophysicists but for particle theorists as well. With our variety of
beyond-the-standard models of the universe we try to account for dark
matter, guess at its properties and explains why it is dark. That last
quality is rather easy to explain, in fact. Our expectation of dark
matter is simply that it does not interact electromagnetically, and so
does not emit photons. If we also posit that it does not interact
strongly, we are left with a particle that can only decay weakly, and so
we might expect a lot of it to stick around. Of course, the particle
must also have a mass, which is the original property we postulated for
it, and so we are looking for the &lt;span class="caps"&gt;WIMP&lt;/span&gt;, the Weakly Interacting Massive
Particle. Schnee talked about the various ways we hope to see WIMPs in
the coming decade, focusing on two avenues, the &lt;span class="caps"&gt;LHC&lt;/span&gt; and passive
detectors trying to pick up cosmic particles passing through the Earth.
WIMPs are by definitions hard to detect, because they interact only
Weakly and thus only weakly. This means that we can&amp;#8217;t actually see them
directly in our detectors, and we have to look for either missing energy
in accelerator results, which we deduce has gone to them, or their
effects on detectable particles in large particle reservoir, much as we
would detect neutrinos. Of course, when we have such weak signals the
art is in reducing the background noise, by putting them underground,
using the least radioactive materials we can find, and so on. The last
part of the talk revolved around two events in his own detector that
seemed to be far enough above background level to be WIMPs . Schnee then
explained how statistical analysis proved in fact these many statistical
outliers were, well, statistically expected, which I found very
interesting. There was also a mention at the very end, of another
experiment called &lt;span class="caps"&gt;DAMA&lt;/span&gt;, which is looking for a &amp;#8220;&lt;span class="caps"&gt;WIMP&lt;/span&gt; wind&amp;#8221;, checking for
signals as the Earth moves through space in opposite directions, in a
kind of modern parallel of the Michelson-Morley experiment. This one has
actually shown a positive signal, though this is of course still
controversial. On Wednesday we had a local postdoc, Enrico Pajer, talk
about Striped holographic superonductor. I mentioned AdS/&lt;span class="caps"&gt;CFT&lt;/span&gt; last week,
and how it&amp;#8217;s induced some crossover between the condensed matter study
of high-temperature superconductors and particle physics. This was one
of those crossover seminars, with a few &lt;span class="caps"&gt;CM&lt;/span&gt; people in the audience.
Enrico spent about half of the talk introducing the audience to the
basics of superconductors - there were a lot of discontent as people
asked questions or had objections to statements which I imagine would
have gone over more smoothly with a condensed matter crowd . The bottom
line of the first half were three important attributes of
high-temperature superconductors, being a strong coupling between the
electrons, the existence of a quantum critical point and an
inhomogeneity of the material. There was then another general
introduction of the AdS/&lt;span class="caps"&gt;CFT&lt;/span&gt; duality, and I&amp;#8217;ll send you to last week&amp;#8217;s
summary (or the rest of the internet) if you want to hear more about
that. Enrico was working on a field theory in AdS space and trying to
apply the results to superconductors through the duality. In particular,
strong coupling and quantum criticalities are known features of the AdS
theory, and the addition here was of striped inhomogeneity, where things
change alone one axis only. This is incorporated into the AdS space by
applying boundary conditions, in particularl to the gauge field in the
relevant field theory, and reading the results by applying Einstein&amp;#8217;s,
Maxwells and the Klein-Gordon equations, in the bulk of the theory. One
interesting feature that was reproduced from other, non-AdS theories,
was the dependence of the critical temperature Tc on the inhomogeneity.
This is the temperature where superconductors turn into normal
conductors, and previous work had shown that it would to drop as the
scale of the inhomogeneity grows either very large or very small, and
have some maximum point for a finite scale of inhomogeneity. Enrico&amp;#8217;s
work showed a dropoff in Tc for inhomogeneity on very small scales,
giving the same qualitative behavior albeit with an exponential rather
than logarithmic dropoff. There were more details and math then, as they
studied these inhomogeneities in the AdS model, trying to determine the
conductivity along the stripes and perpendicular to them and so on,
producing some promising results and promising to produce some more.
Finally on Friday we had Kuver Sinha of Texas A&amp;amp;M talk about The
Cosmological Moduli Problem and Non-thermal Histories of the Universe.
As mentioned above, this talk revolved around dark matter as well,
though from a particle theory perspective. The trick in particle physics
is always making sure that your solution to one problem, in this case
dark matter, does not interfere with our solution to another problem.
The other problem here was the baryon asymmetry, or the overabundance of
matter compared with antimatter in the universe. In particle physics the
two are generally sides of the same coin and we have no reason to prefer
one or the other, and so we must have some reason that we only observe
regular matter in the universe. There is a well-established model for
this, called nucleosynthesis, and now when we explain the amount of dark
matter in the universe we have to keep from interfering with it. And
while we&amp;#8217;re at it, we might solve a third problem - why is the density
of dark matter and regular matter in the universe on the same order of
magnitude? Sinha went through this, presenting two models of baryon
genesis, occurring at different times in the history of the universe,
each with their own features problems. Finally, he suggested one
solution to the coincidence problem that is non-thermal - that is,
rather than configuring the equilibrium point of matter and dark matter
to be similar separately, we have them coming from the same source with
similar decay rate. And that was that for last week, as dark matter
obscures the better-lit one. This week have a sweeping overview of
particle physics, toric singularities on branes, and possibly some news
from the &lt;span class="caps"&gt;LHC&lt;/span&gt;. See you in&amp;nbsp;seven.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Your Week in Seminars: Conformal Edition</title><link href="/posts/your-week-in-seminars-conformal-edition.html" rel="alternate"></link><updated>2010-11-01T17:58:00-04:00</updated><author><name>Yariv</name></author><id>tag:,2010-11-01:posts/your-week-in-seminars-conformal-edition.html</id><summary type="html">&lt;p&gt;Another week has gone by here in Cornell. The last leaves are turning
red, a hint of snow passed us on the weekend, and the undergrads have
hit the streets and parties in minimal clothing, then did the same again
next day wearing a set of cat ears. And in the physics department, we
had the usual three talks. On Monday, the colloquium speaker was Holger
Müller from &lt;span class="caps"&gt;UC&lt;/span&gt; Berkeley, talking about Gravitational Redshift,
Equivalence Principle, and Matter Waves. The center of the talk was
Muller&amp;#8217;s experimental device, an atom interferometer. Many of you will
remember the Michelson-Morley interferometer, the device used to
disprove the existence of the ether. A light-interferometer essentially
takes a beam of light, splits it in two and then merges it back again,
using the result of the interference between the two parts to learn
something about the relative difference between the optical paths taken
by the two. The atom interferometer, then, performs a similar function
with atom wavefunctions. An atom is shot up into the air and a laser is
directed towards it and calibrated to interact with the atom half the
time. The atom&amp;#8217;s wavefunction is split two trajectories, at the end of
which another laser is calibrated to bring the two paths back together.
The detector can then measure the path difference between the two
trajectories, and as we have excellent ways of measuring time and the
mass and energy of the atom, this amounts to a very accurate measurement
of g, the free-fall constant. Muller went on to show how his team has
been using the interferometer to perform very accurate measurements of
General Relativity, from its isotropy to the universality of free fall
motion for objects of different masses. There were some neat tricks
described, and they mentioned the ability to measure those &lt;a href="http://thevirtuosi.blogspot.com/2010/09/microseconds-and-miles_7470.html"&gt;minute
differences&lt;/a&gt;
in gravity experienced by moving the system one meter upwards. It&amp;#8217;s
always a little difficult to get excited about tests that confirm an
accepted theory, especially one like General Relativity, but I think
this is important work. To paraphrase the words of fellow Virtuos Jared,
&lt;span class="caps"&gt;GR&lt;/span&gt; is always going to be right up until we find where it breaks. On
Wednesday, David Kaplan talked about Conformality Lost. This talk was
about &lt;span class="caps"&gt;QCD&lt;/span&gt;, but not about &lt;span class="caps"&gt;QCD&lt;/span&gt;. One of the features of &lt;span class="caps"&gt;QCD&lt;/span&gt;, or really
field theories in general, is the running of the coupling constants.
Where in classical theories the strength of the interaction between two
particles is constant and depends only on the distance between them,
field theory shows us how the strength of the interaction changes with
the energy of the participating particles. This is crucial, for
instance, for theories of grand unification that posit that the known
forces are all the same at very high energies. In &lt;span class="caps"&gt;QCD&lt;/span&gt;, in particular,
the running of the constant also has to with confinement and asymptotic
freedom. Confinement is the notion that quarks can never break free of
each other, and so we never observe them alone in nature, only within
particles such as protons, neutrons, baryons and mesons. Asymptotic
freedom is the notion that at high energies, if we collide another
particle with a quark, it behaves as if it was free of other influence.
If we associate long distances with low energy and short distances with
high energy, we can see how the coupling must flow from very small at
one end to very large at the other end. One of the interesting things
about the running of the coupling is that it defines a scale for the
theory. If the coupling is different for particles of energy E~1~ and
E~2~, then we can choose some value of the coupling and describe our
energy in relation to the energy relative to this scale. Theories
without running coupling are called conformal and have no natural scale.
&lt;span class="caps"&gt;QCD&lt;/span&gt;, it seems, behave this way if you take it all the way to asymptotic
freedom. Kaplan talked about the investigation of this conformal stage
of the theory, its existence and inexistence. As an analog he showed a
quantum-mechanical system of a particle in a Coulombic, potential. The
minimum energy of this system is given by solution of a quadratic
equation, which can have either two solutions, one or none, depending on
the relation between the mass of the particle and the strength of the
potential. A scale exists in this case only if there are two solutions:
a single energy is meaningless, of course, because we can always add a
constant, but if there&amp;#8217;s two of them then the difference defines a
scale. This toy model, it turns out, can be analogous to a &lt;span class="caps"&gt;QCD&lt;/span&gt; with the
equivalent parameter being the relative number of flavors (kind of
particles) and colors (different charges in the theory, red, blue and
green in our regular &lt;span class="caps"&gt;QCD&lt;/span&gt;). There were a number of interesting results
from this model, the most exciting one, perhaps, being the possible
existence of a &amp;#8220;mirror&amp;#8221; &lt;span class="caps"&gt;QCD&lt;/span&gt; theory beyond the conformal point of &lt;span class="caps"&gt;QCD&lt;/span&gt;, a
sort of theory with a different number of colors and different gauge
groups. Kaplan ended his talk by talking of at least one possible
candidate for this mirror theory that they had recently found. Finally,
on Friday, we had Ami Katz from Boston University talk about &lt;span class="caps"&gt;CFT&lt;/span&gt;/AdS.
AdS/&lt;span class="caps"&gt;CFT&lt;/span&gt; has been a big buzzword for the last decade or so. The &lt;span class="caps"&gt;CFT&lt;/span&gt; here
stands for conformal field theory of the kind mentioned in the previous
summary, and AdS stands for Anti-de Sitter space, a geometry of
spacetime possible in general relativity. The slash in between stands
for a duality that allows results from one theory to be interpreted in
the other and vice versa. This has some exciting implications since it
allows us to use each theory in the regime where we can solve it.
Particle theorists are, in general, trying to use the &lt;span class="caps"&gt;CFT&lt;/span&gt; to solve for
high-energy theories that behave like AdS. Katz had apparently rewritten
the duality as &lt;span class="caps"&gt;CFT&lt;/span&gt;/AdS, to signal that he was asking the opposite
question, starting with a &lt;span class="caps"&gt;CFT&lt;/span&gt; and asking whether it is a good fit for
the duality. A large part of the talk was dedicated to making an analogy
from CFTs into conventional field theories. We know pretty well when a
field theory is a good description of reality and when it tends to break
down. This has to do, usually, with some cutoff energy, a scale at which
new physics comes into play. As long as we stay at energies far below
that cutoff, the effects of the unknown physics will be a small
correction to the calculations we make with our known physics. In CFTs,
we had just said, there is no energy scale, and so the question must be
different. The relevant question, apparently, is the dimensionality of
operators - not what their energy scale is, but how they scale with a
change of energy. For instance, a derivative behaves like inverse
distance, and distance behaves like inverse energy, so a single
derivative scales linearly in energy, while a double derivative scale
quadratically. I didn&amp;#8217;t understand much past the half-point of this
lecture, but the bottom line appeared to be that a well-behaved &lt;span class="caps"&gt;CFT&lt;/span&gt; has
a gap in its operators dimensionality, allowing us to focus on one
operator and plenty of its derivatives before coming to the scaling of
the next operator. This kind of gap allows our perturbative corrections
to remain perturbative when we go to the AdS side. That&amp;#8217;s it for last
week, with its conformal ups and down. As usual, we&amp;#8217;re past the first
seminar of the new week, which was non-wimpy talk about WIMPs. Still
ahead this week are superconductors (and more AdS/&lt;span class="caps"&gt;CFT&lt;/span&gt;, presumably) and
some non-thermal histories of the universe. (that is, of course, if I
don&amp;#8217;t freeze first - temperatures have dropped below zero already. It&amp;#8217;s
so much colder when you work in&amp;nbsp;Celsius)&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Your Week in Seminars Fermionic Edition</title><link href="/posts/your-week-in-seminars-fermionic-edition.html" rel="alternate"></link><updated>2010-10-25T11:56:00-04:00</updated><author><name>Yariv</name></author><id>tag:,2010-10-25:posts/your-week-in-seminars-fermionic-edition.html</id><summary type="html">&lt;p&gt;Good evening, and welcome to the second edition of YWiS. Last week I
took in the full range of seminars, from colloquium to Friday lunch. I
don&amp;#8217;t know if I can say I took in the full content of these talks as
well, but let&amp;#8217;s see what I learned On Monday we had Andrew Millis from
Columbia University talk about Materials with Strong Electronic
Correlations: The (Theoretical) End of the Beginning? (I think the
subtitle wasn&amp;#8217;t actually there in the talk itself). This was a condensed
matter theory talk, and like all condensed matter talks it started off
with the phase diagram for cuprates and a mention of the illustrious
pseudogap, the Dark Energy of condensed matter. The pseudogap is a phase
of cuprates - the materials that make high-temperature superconductors -
that occurs at about the same concentration of defects as
superconductivity but at a higher temperature. It is a little-understood
phase that sits between two well-understood phases (antiferromagnetism
and Fermi liquid) and perhaps holds some answers to the nature of
high-temperature superconductivity. Millis started with the pseudogap
picture and a short overview of the current state of condensed matter
theory. He claimed that perhaps some of the phases of matter in question
have local, short-range ordering, but no overarching long-range order in
the system, and that the investigation of these phases should take this
into account. At the end of this introduction he asked why we cannot
easily solve the problems of condensed matter. The basic equations that
govern the interactions in the field are known - the electromagnetic
potential and Schrödinger&amp;#8217;s equation - and we should be able to just
plug them into a computer and calculate away. The trouble, as Millis
presented it, comes from the fermionic nature of the problem. What we&amp;#8217;re
trying to calculate, in metals, is the behavior of the electrons running
through the bulk of the metal. Electrons are fermions, which means that
no two can have the same quantum numbers, that is no two can be in the
same place with the same momentum and spin. It turns out that the
configurations with lowest energies tend to be symmetric, with many
particles in the same position. Finding low-energy configurations that
put every particle in a different place is much harder. I didn&amp;#8217;t get a
lot more from this talk. Millis went on to suggest a method that avoids
tackling the problem directly, but rather solves an analogous one that
we can translate to into a solution. I believe that there was some talk
of a local, rather than global, solution, and of the Hubbard model,
which is a popular approximation used in modeling electrons in a solid.
I phased in and out of this talk, but I&amp;#8217;d peg my Understanding at 25
minutes, and my Interest at about 35 minutes. The Wedenesday particle
talk was by Jesse Thaler from &lt;span class="caps"&gt;MIT&lt;/span&gt;. He talked about Aspects of Goldstini.
Goldstini is the Italian plural form of goldstino, which is the
fermionic version - we put &amp;#8220;ino&amp;#8221; at the end of fermionic particles,
influenced by the neutrino - of the Goldstone boson. A Goldstone boson
is a massless particle that we find in theories of spontaneous symmetry
breaking. Spontaneous symmetry breaking is a popular concept in particle
physics, which springs from the concept of an unstable energy maximum.
Imagine a pencil standing on its tip, a system which is symmetric in
every direction. The pencil is unstable, though, and left by itself it
would fall down in any one of the equivalent directions around it. Once
it has fallen, it&amp;#8217;s broken the symmetry and created one preferred
direction. Thus the symmetry of the system is broken when one direction
is chosen spontaneously. This sort of thing is at the bottom of our
understanding the electroweak force, and pops up quite a bit in particle
physics. When it does, we expect a Goldstone boson, a massless particle
that roughly corresponds to spinning the fallen-down pencil around its
tip. The goldstini is the fermionic version of that particle which
springs from the breaking of supersymmetry - the symmetry that relates
fermions and bosons. The goldstino, then, is well known and accepted in
common theories of supersymmetry. It breaks supersymmetry, and then
interacts with the gravitino - another fermion, which mediates the force
of gravity - to become massless. Thaler&amp;#8217;s work posits more than one
goldstino, hence, goldstini. How can we have more than one goldstino? By
breaking supersymmetry more than once. We do this by imagining several
&amp;#8220;sectors&amp;#8221; in our theory, different sets of fields (particles) that break
supersymmetry but don&amp;#8217;t interact with each other significantly. When you
work through this model it turns out that you can have several
goldstini. Also, as the original goldstini lost its mass by giving it to
the gravitino, and the gravitino is now satisfied, the new goldstini get
to keep their mass, which turns out to be exactly twice that of the
(satisfied) gravitino. Thaler then discussed three possible scenarios
for this mass, and what we would expect to see at the &lt;span class="caps"&gt;LHC&lt;/span&gt; in each case.
The important thing, it turns out, is how this mass compares with that
of the lightest ordinary superpartner, the first supersymmetry-related
particle we expect to see in the &lt;span class="caps"&gt;LHC&lt;/span&gt;. If the mass of the goldstini is
very small, they will not come into play as the &lt;span class="caps"&gt;LOSP&lt;/span&gt; will decay into
particles we already know. If the mass of the goldstini is too large,
then the &lt;span class="caps"&gt;LOSP&lt;/span&gt; cannot decay into it. But if the mass is in some
goldstinilocks region in-between, things become interesting and we can
expect to see evidence of the gravitino and the goldstini, and
distinctly see one having double the mass of the other. I followed a
good portion of this talk, with Understanding of 30 minutes all in all,
and perhaps 45 minutes of interest. Finally, the Friday particle theory
lunch had a talk by our own David Curtin, one of Csaba&amp;#8217;s grad students.
He talked about Solving the gaugino mass problem in Direct Gauge
Mediation. I came into this one to follow more of it, on account of the
speaker being a student, but ended up following very little as it was
technical and above my level. It revolved, again, around supersymmetry
breaking. David does model building, which means he starts out with some
acceptable results, i.e. the universe as we know it, and tries to tinker
up a combination of particles and interactions that would reproduce it,
one portion at a time. What he was trying to build this time was a
metastable level in the broken supersymmetric potential. If we think
back to our pencil, we had an unstable maximum, the pencil standing on
its tip, and a minimum point, the pencil laying on the table, from which
it cannot fall. But we can also imagine a midpoint - perhaps resting one
side of the pencil on a book. It can&amp;#8217;t fall any further right away, but
there is another, preferred position lying flat on the table. That&amp;#8217;s
what we call a metastable energy level. As it turns out, the metastable
level has some desirable outcomes within the context of supersymmetry,
and the talk revolved around the ways we have of getting the right
energy structure to our system while avoiding things we don&amp;#8217;t want in
our models - arbitrary particle masses, a large number of new particles,
or anything blatantly unphysical. My Understanding here was quite close
to 0, as the technicalities were beyond me. (in fact, the pre-seminar
discussion was about soccer, so one might say my understanding was
negative). I probably kept trying to follow for about half the talk, or
30 minutes. That&amp;#8217;s it for last week. This week we can expect gravity,
(heavy!) Conformality Lost (literary!) and &lt;span class="caps"&gt;CFT&lt;/span&gt;/AdS (buzzwordy!). And
hopefully less headscratching and more nodding in a&amp;nbsp;agreement.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Paradigm Shifts 3: With a Vengence</title><link href="/posts/paradigm-shifts-3-with-a-vengence.html" rel="alternate"></link><updated>2010-10-21T14:32:00-04:00</updated><author><name>Sam</name></author><id>tag:,2010-10-21:posts/paradigm-shifts-3-with-a-vengence.html</id><summary type="html">&lt;p&gt;The last shift I wanted to present is best explained at
&lt;a href="http://tauday.com/"&gt;http://tauday.com/&lt;/a&gt; . There you will find a
manifesto (yes, a manifesto) about why we should change from using &lt;mathjax&gt;$$
\\pi = \\text{180 degrees} $$&lt;/mathjax&gt; as the circle constant to &lt;mathjax&gt;$$ \\tau = 2
\\pi = \\text{360 degrees} $$&lt;/mathjax&gt; It&amp;#8217;s quite a convincing argument, and it&amp;#8217;s
a shift that can easily be made. Check the website for more. &lt;span class="caps"&gt;TAU&lt;/span&gt; &lt;span class="caps"&gt;VS&lt;/span&gt; &lt;span class="caps"&gt;PI&lt;/span&gt;
&lt;a href="http://tauday.com/images/figures/tau-angles.png"&gt;&lt;img alt="image" src="http://tauday.com/images/figures/tau-angles.png" /&gt;&lt;/a&gt;&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Your Week in Seminars Intro Edition</title><link href="/posts/your-week-in-seminars-intro-edition.html" rel="alternate"></link><updated>2010-10-18T12:50:00-04:00</updated><author><name>Yariv</name></author><id>tag:,2010-10-18:posts/your-week-in-seminars-intro-edition.html</id><summary type="html">&lt;p&gt;We&amp;#8217;ve done a lot of talking over the past few months here on the
Virtuosi, but one important subject has not come up so far. An issue
that is central to the day to day life of the average grad student. The
subject of free food. The average graduate student in an American
university shops for food 0.7 times per semester, paying a total of
$13.22. He eats an average of three vegetables and one fruit, all at
home during Thanksgiving. He turns his oven on once per year while
trying to ascertain if the power is out or the light bulb in the kitchen
needs to be replaced. The rest of his nutrition is made up entirely of
free donuts, bagels and pizza. The place to get all this free food,
naturally, is various department talks and seminars. And while we&amp;#8217;re
there, we may as well try to learn some physics. With that noble goal in
mind, I&amp;#8217;d like to welcome you to the first edition of Your Week in
Seminars, where I shall endeavor to relay the content of the weekly
seminars I attend in Cornell. On an average week this will be one
general interest colloquium and two particle theory talks. One of my
colleagues may want to take up the &lt;span class="caps"&gt;LASSP&lt;/span&gt; (Condensed Matter) talk or any
of the other seminars going around in the department I&amp;#8217;ll try to relate
what I got out of each talk, with more words than equations and with no
figures. I&amp;#8217;ll aim for a general audience level but I think I&amp;#8217;m likely to
end up at a physics undergrad or a popular-science-savvy level, as
technical terms are bound to be thrown about. If there&amp;#8217;s one you don&amp;#8217;t
know, feel free to ask over in the comments or take this as an
opportunity to delve into Wikipedia. I&amp;#8217;ll also provide two handy metrics
to the quality of the talk, my Interest Level, defined as the amount of
time before I start playing with my phone, and my Comprehension level,
defined as the amount of time where I was still following the speaker.
Last week there was no colloquium due to Fall break, so this post will
cover just the Wednesday and Friday &lt;a href="http://lepp.cornell.edu/Events/ParticleTheory/WebHome.html"&gt;particle
seminars&lt;/a&gt;.
On Wednesday we had David Kagan from Columbia University tell us about
Conifunneling - Stringy Tunneling Between Flux Vacua. As you may know,
string theory demands that our universe have a large number of
dimensions, generally 10 or 11, to avoid such nastiness mass particles.
To bridge the gap between the theoretical and observed number of
dimensions (four) one has to &amp;#8220;compactify&amp;#8221; the extra dimensions, that is,
to posit that they have some shape and size and write down an effective
four-dimensional theory that takes their presence into account. This
compactification creates an energy surface, or some effective potential
in space. What we call &amp;#8220;vacuum&amp;#8221;, the ground state of the universe, rests
in one of the minimum points of that potential, as ground levels are
wont to do. But it need not be the absolute minimum, just a local one,
and where there are local minima in a quantum theory we know that there
is also tunneling. Kagan, then, talks of tunneling between these local
energy minima created by compactification of the extra dimensions of
string theory. This tunneling, from what I gathered, can be described as
an evolution in time of the manifold, the geometric layout of spacetime.
The main conceit of the talk was that this evolution takes the manifold
into the form of a &amp;#8220;conifold&amp;#8221;, which is a manifold with a conic
singularity. This conifold then nucleates a 5d-brane; branes are a
objects in string theory that have some dimensionality less than that of
the entire spacetime. After creating this object, the conifold
transforms back into a non-singular manifold, but one where the vacuum
is in another energy minimum. We can visualize this process by thinking
of spacetime as an elastic sheet of of sorts, pinched at a point and
pulled. It is deformed, creating an elongated cone-like area, until
finally it tears, emitting a five-dimensional brane, and reverting back
to its original form. There was some discussion at the end which mostly
went over my head, but at some point Henry Tye, Liam and Maxim were
trying to figure out whether the tunneling is necessarily done via a
conifold or whether Kagan was just describing what happens if it does.
The conclusion, I believe, was that it is the latter case, though Kagan
said they have some good arguments on why the conifold tunneling had to
happen. Interest: 40 minutes. Understanding: 20 minutes. On Friday we
had Zvi Lipkin from the Weizmann Institute tell us about Heavy quark
hadrons and exotics, a challenge for &lt;span class="caps"&gt;QCD&lt;/span&gt;. This talk revolved around the
constituent quark model for &lt;span class="caps"&gt;QCD&lt;/span&gt;. Our usual picture of hadrons is one of
two or three valence quarks sitting in a sea of gluons and virtual
quark-antiquark pairs, due to the strong interactions of Strong
Interaction. Lipkin&amp;#8217;s work focuses on trying to abstract this sea away
and focus on the valence quarks as if we were discussing a
hydrogen-atom-like system of two particles and a potential between them.
This kind of treatment allows us to maximize the use of flavor
symmetries. Flavor is &lt;span class="caps"&gt;QCD&lt;/span&gt;-speak for &amp;#8220;type of particle&amp;#8221;, that is, up,
down, strange, charm and bottom quarks. Using the constituent quark
model we may be able to say things like &amp;#8220;the difference between the
B^0^~s~ and the B^0^ (mesons made up of an anti-b and an s or d quark,
respectively) is the same as the difference between the Ξ^0^ and the
Σ^0^&amp;#8221; (baryons made up of uss and uds quarks, respectively). (Don&amp;#8217;t take
that last example too seriously - I made it up by looking at lists of
baryons and mesons. But that was the gist of the talk) Lipkin showed
done by him and Marek Karliner, (who taught me differential equations in
Tel Aviv) including lots of numbers nicely matching between their theory
and experiment as well as a less-convincing attempt to characterize the
two-body potential in this two-body problem. At the end of the talk he
also mentioned the X(3872) seen by the Belle experiment. This is a
particle that does not seem to fit into our regular models as either a
baryon or a meson, and Lipkin suggested that this might be a
&amp;#8220;tetraquark,&amp;#8221; a combination of two quarks and two antiquarks. This kind
of exotic hadron has been talked about for a long time, and there was
some excitement a few years ago with the discovery and eventual
un-discovery of the Θ^+^ pentaquark. (made up of four quarks and an
antiquark) Interest: 60 minutes. (I was sitting in the front and could
not politely take out the phone) Understanding: 60&amp;nbsp;minutes.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Quantum Chess!</title><link href="/posts/quantum-chess-.html" rel="alternate"></link><updated>2010-09-08T21:48:00-04:00</updated><author><name>Sam</name></author><id>tag:,2010-09-08:posts/quantum-chess-.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.showiphonewallpapers.com/iPhonewallpapers/20102/iphonewallpapers/Chess-20100726.jpg"&gt;&lt;img alt="image" src="http://www.showiphonewallpapers.com/iPhonewallpapers/20102/iphonewallpapers/Chess-20100726.jpg" /&gt;&lt;/a&gt;
Ever find out when you&amp;#8217;re playing chess that the Queen you reached for
is actually a pawn? Probably not. But most chess games aren&amp;#8217;t affected
by the weirdness of the quantum world. This one is:
&lt;a href="http://research.cs.queensu.ca/Parallel/QuantumChess/QuantumChess.html"&gt;http://research.cs.queensu.ca/Parallel/QuantumChess/QuantumChess.html&lt;/a&gt;&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Solar Sails Addendum I</title><link href="/posts/solar-sails-addendum-i.html" rel="alternate"></link><updated>2010-05-16T23:28:00-04:00</updated><author><name>Corky</name></author><id>tag:,2010-05-16:posts/solar-sails-addendum-i.html</id><summary type="html">&lt;p&gt;As requested, below is an explicit evaluation of the silly looking
integral in &lt;a href="http://thevirtuosi.blogspot.com/2010/05/solar-sails-i.html"&gt;Solar Sails
I&lt;/a&gt;. If you
just want some hints to do the integral, see &lt;a href="http://thevirtuosi.blogspot.com/2010/05/solar-sails-addendum-ii.html"&gt;Solar Sails Addendum
&lt;span class="caps"&gt;II&lt;/span&gt;&lt;/a&gt;.
Here we present a step-by-step solution of the differential equation: &lt;mathjax&gt;$$
\\frac{dr}{dt} = \\left[ \\frac{2\\alpha}{m} \\left( \\frac{1}{r\_0} -
\\frac{1}{r} \\right)\\right]\^{1/2} $$&lt;/mathjax&gt; This is just a separable
equation, so we rearrange to get an integral equation: &lt;mathjax&gt;$$
\\int\_{r\_0}\^{r\_f} \\frac{dr}{\\left[ \\frac{2\\alpha}{m} \\left(
\\frac{1}{r\_0} - \\frac{1}{r} \\right)\\right]\^{1/2}}
=\\int\_{0}\^{t}dt$$&lt;/mathjax&gt; We see that the right hand side here will just
evaluate to t. Let&amp;#8217;s rearrange the left hand side to get the integration
variable to be dimensionless. This is important because it allows the
integral to just be a number, with all the unit-dependent terms pulled
outside. So we have &lt;mathjax&gt;$$ \\int\_{r\_0}\^{r\_f} \\frac{dr}{\\left[
\\frac{2\\alpha}{mr\_0} \\left( 1 - \\frac{r\_0}{r}
\\right)\\right]\^{1/2}} =t$$&lt;/mathjax&gt; \noindent Now we can do a change of
variables to get the dimensionless variable u = r/r0. This is just
giving us our distance in terms of our initial distance. In the problem
I took r_0 to be 1 &lt;span class="caps"&gt;AU&lt;/span&gt;. So u just gives our distance now in terms of &lt;span class="caps"&gt;AU&lt;/span&gt;:
&lt;mathjax&gt;$$ \\int\_{1}\^{u\_f} \\frac{du}{\\left[ \\frac{2\\alpha}{m{r\_0}\^3}
\\left( 1 - \\frac{1}{u} \\right)\\right]\^{1/2}} =t$$&lt;/mathjax&gt; So lets set &lt;mathjax&gt;$$ k
= (m{r\_0}\^3}/{2 \\alpha)\^{1/2} ,$$&lt;/mathjax&gt; which just gives &lt;mathjax&gt;$$
k\\int\_{1}\^{u\_f} \\frac{du}{\\left[ \\left( 1 - \\frac{1}{u}
\\right)\\right]\^{1/2}} =t$$&lt;/mathjax&gt; Now we are ready to get started!
Typically, when I see something with a square root in the denominator
that&amp;#8217;s giving me trouble, I just blindly try trig substitutions. Let&amp;#8217;s
try u = [csc(x)]\^2, so 1/u = [sin(x)]\^2 and du = -(csc x)\^2 * cot x,
and &lt;mathjax&gt;$$ \\int\_{1}\^{u\_f} \\frac{du}{\\left[ \\left( 1 - \\frac{1}{u}
\\right)\\right]\^{1/2}} =\\int\_{x\_0}\^{x\_f} \\frac{-2\\csc\^2x \\cot
x dx}{\\left(1-\\sin\^2x \\right)\^{1/2}} = \\int\_{x\_0}\^{x\_f}
-2\\csc\^3x dx ,$$&lt;/mathjax&gt; where x_0 = pi/2 and x_f = arcsin u_f . The last
equality above just comes from simplifying the trig expressions. So now
how do we solve this &amp;#8220;easier&amp;#8221; problem? As a wise man once said, &amp;#8220;When in
doubt, integrate by parts.&amp;#8221; So let&amp;#8217;s try that. Expanding out a bit we
see that: &lt;mathjax&gt;$$ -\\int\_{x\_0}\^{x\_f} \\csc\^3x dx =
\\int\_{x\_0}\^{x\_f}\\csc x \\left(-\\csc\^2x \\right)dx $$&lt;/mathjax&gt; Remembering
that integration by parts goes like &lt;mathjax&gt;$$ \\int u dv = uv - \\int v du $$&lt;/mathjax&gt;
we can set u = csc x and v = \cot x&lt;mathjax&gt;$ to get $&lt;/mathjax&gt;&lt;mathjax&gt;$
\\int\_{x\_0}\^{x\_f}\\csc x \\left(-\\csc\^2x \\right)dx = \\csc x
\\cot x \\Big |\_{x\_0}\^{x\_f} - \\int\_{x\_0}\^{x\_f} \\cot x
\\left(-\\csc x \\cot x \\right) dx $&lt;/mathjax&gt;&lt;mathjax&gt;$ which is just $&lt;/mathjax&gt;&lt;mathjax&gt;$
-\\int\_{x\_0}\^{x\_f}\\csc\^3x dx = \\csc x \\cot x \\Big
|\_{x\_0}\^{x\_f} + \\int\_{x\_0}\^{x\_f} \\cot\^2 x \\csc x dx $&lt;/mathjax&gt;&lt;mathjax&gt;$
Remembering that $&lt;/mathjax&gt;&lt;mathjax&gt;$ \\cot\^2 x = \\csc\^2 x -1 ,$&lt;/mathjax&gt;&lt;mathjax&gt;$ we have $&lt;/mathjax&gt;&lt;mathjax&gt;$
-\\int\_{x\_0}\^{x\_f}\\csc\^3x dx = \\csc x \\cot x \\Big
|\_{x\_0}\^{x\_f} + \\int\_{x\_0}\^{x\_f} \\left(\\csc\^2 x - 1 \\right)
\\csc x dx $&lt;/mathjax&gt;&lt;mathjax&gt;$ which we can expand to $&lt;/mathjax&gt;&lt;mathjax&gt;$ -\\int\_{x\_0}\^{x\_f}\\csc\^3x
dx = \\csc x \\cot x \\Big |\_{x\_0}\^{x\_f} - \\int\_{x\_0}\^{x\_f}
\\csc x dx + \\int\_{x\_0}\^{x\_f} \\csc\^3 x dx$&lt;/mathjax&gt;&lt;mathjax&gt;$ But this is just what
we want! Rearranging we now have that $&lt;/mathjax&gt;&lt;mathjax&gt;$
-2\\int\_{x\_0}\^{x\_f}\\csc\^3x dx = \\csc x \\cot x \\Big
|\_{x\_0}\^{x\_f} - \\int\_{x\_0}\^{x\_f} \\csc x dx$&lt;/mathjax&gt;&lt;mathjax&gt;$ Remembering that
the integral for csc is $&lt;/mathjax&gt;&lt;mathjax&gt;$ \\int \\csc x dx =-\\ln | \\csc x + \\cot x|
+ C $&lt;/mathjax&gt;&lt;mathjax&gt;$ and evaluating our limits we have that $&lt;/mathjax&gt;&lt;mathjax&gt;$
-2\\int\_{x\_0}\^{x\_f}\\csc\^3x dx = \\csc x\_f \\cot x\_f - \\csc x\_0
\\cot x\_0 +\\ln \\left( \\frac{| \\csc x\_f + \\cot x\_f|}{| \\csc x\_0
+ \\cot x\_0|} \\right) $&lt;/mathjax&gt;&lt;mathjax&gt;$ Now we just need to evaluate at x\_0 = pi/2
and x\_f = arcsin u\_f. We can draw a right triangle with far angle
x\_f, hypoteneuse of length sqrt{u}, and legs of length 1 and sqrt{u-1}
to see that csc x\_f = sqrt{u} and cot x\_f = sqrt{u-1}, so $&lt;/mathjax&gt;&lt;mathjax&gt;$
-2\\int\_{x\_0}\^{x\_f}\\csc\^3x dx = \\sqrt{u}\\sqrt{u-1} + \\ln{ |
\\sqrt{u} + \\sqrt{u-1}|} $&lt;/mathjax&gt;&lt;mathjax&gt;$ And this is what we have sought from the
beginning. Using the last two equations on the first page we see that $&lt;/mathjax&gt;&lt;mathjax&gt;$
t = k\\int\_{1}\^{u\_f} \\frac{du}{\\left[ \\left( 1 - \\frac{1}{u}
\\right)\\right]\^{1/2}} = k\\left[-2\\int\_{x\_0}\^{x\_f}\\csc\^3x dx
\\right] = k \\left[\\sqrt{u}\\sqrt{u-1} + \\ln{ | \\sqrt{u} +
\\sqrt{u-1}|} \\right] $&lt;/mathjax&gt;&lt;mathjax&gt;$ Plugging back in our value of k, we have $&lt;/mathjax&gt;&lt;mathjax&gt;$ t
= \\left(\\frac{m{r\_0}\^3}{2\\alpha}
\\right)\^{1/2}\\left[\\sqrt{u}\\sqrt{u-1} + \\ln{ | \\sqrt{u} +
\\sqrt{u-1}|} \\right] $&lt;/mathjax&gt;&lt;mathjax&gt;$ Simplifying a bit and dropping the absolute
value bars since u will always be bigger than u-1, we have our final
answer: $&lt;/mathjax&gt;&lt;mathjax&gt;$ t = \\left(\\frac{m{r\_0}\^3}{2\\alpha}
\\right)\^{1/2}\\left[\\sqrt{u(u-1)} + \\ln{ \\left( \\sqrt{u} +
\\sqrt{u-1}\\right)} \\right] $&lt;/mathjax&gt;$ where u = r / r_0 is our
non-dimensional distance measurement. And this is (up to some
rearranging) exactly what we get in the initial&amp;nbsp;post.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Solar Sails Addendum II</title><link href="/posts/solar-sails-addendum-ii.html" rel="alternate"></link><updated>2010-05-16T23:27:00-04:00</updated><author><name>Corky</name></author><id>tag:,2010-05-16:posts/solar-sails-addendum-ii.html</id><summary type="html">&lt;p&gt;This is the schematic version, if you just wanted hints. The full
solution is given in &lt;a href="http://thevirtuosi.blogspot.com/2010/05/solar-sails-addendum-i.html"&gt;Solar Sails Addendum
I&lt;/a&gt;.
Here we present a schematic solution of the differential equation: &lt;mathjax&gt;$$
\\frac{dr}{dt} = \\left[ \\frac{2\\alpha}{m} \\left( \\frac{1}{r\_0} -
\\frac{1}{r} \\right)\\right]\^{1/2} $$&lt;/mathjax&gt; This is just a separable
equation, so we rearrange to get an integral equation: &lt;mathjax&gt;$$
\\int\_{r\_0}\^{r\_f} \\frac{dr}{\\left[ \\frac{2\\alpha}{m} \\left(
\\frac{1}{r\_0} - \\frac{1}{r} \\right)\\right]\^{1/2}} =
\\int\_{0}\^{t}dt$$&lt;/mathjax&gt; From here it&amp;#8217;s nice to non-dimensionalize, so our
integration variable is just a number (with no units attached). This
allows us to get the integral into a form like &lt;mathjax&gt;$$ k\\int\_{1}\^{u\_f}
\\frac{du}{\\left[ \\left( 1 - \\frac{1}{u} \\right)\\right]\^{1/2}} =
t$$&lt;/mathjax&gt; for appropriate values of k and u. Now we are ready to get started!
Typically, when I see something with a square root in the denominator
that&amp;#8217;s giving me trouble, I just blindly try trig substitutions. After
an appropriate trig substitution, we get something of the form &lt;mathjax&gt;$$
\\int\_{1}\^{u\_f} \\frac{du}{\\left[ \\left( 1 - \\frac{1}{u}
\\right)\\right]\^{1/2}} = \\int\_{x\_0}\^{x\_f} -2\\csc\^3x dx$$&lt;/mathjax&gt;, So
now how do we solve this &amp;#8220;easier&amp;#8221; problem? As a wise man once said,
&amp;#8220;When in doubt, integrate by parts.&amp;#8221; So let&amp;#8217;s try that. &lt;mathjax&gt;$$ \\left[
\\mbox{HINT:} -\\int\_{x\_0}\^{x\_f} \\csc\^3x dx =
\\int\_{x\_0}\^{x\_f}\\csc x \\left(-\\csc\^2x \\right)dx \\right]$$&lt;/mathjax&gt;
Remembering that integration by parts goes like &lt;mathjax&gt;$$ \\int u dv = uv -
\\int v du $$&lt;/mathjax&gt; we can pick appropriate values of u and v to get something
nice, which eventually leads to &lt;mathjax&gt;$$ -\\int\_{x\_0}\^{x\_f}\\csc\^3x dx =
\\csc x \\cot x \\Big |\_{x\_0}\^{x\_f} - \\int\_{x\_0}\^{x\_f} \\csc x
dx + \\int\_{x\_0}\^{x\_f} \\csc\^3 x dx$$&lt;/mathjax&gt; But this is just what we
want! Rearranging we now have that &lt;mathjax&gt;$$ -2\\int\_{x\_0}\^{x\_f}\\csc\^3x
dx = \\csc x \\cot x \\Big |\_{x\_0}\^{x\_f} - \\int\_{x\_0}\^{x\_f}
\\csc x dx$$&lt;/mathjax&gt; Evaluating our integrals, we see that &lt;mathjax&gt;$$
-2\\int\_{x\_0}\^{x\_f}\\csc\^3x dx = \\sqrt{u}\\sqrt{u-1} + \\ln{ |
\\sqrt{u} + \\sqrt{u-1}|} $$&lt;/mathjax&gt; And this is what we have sought from the
beginning. Plugging back in to our earlier equations and rearranging
gives &lt;mathjax&gt;$$ t = \\left(\\frac{m{r\_0}\^3}{2\\alpha}
\\right)\^{1/2}\\left[\\sqrt{u(u-1)} + \\ln{\\left( \\sqrt{u} +
\\sqrt{u-1}\\right)} \\right] $$&lt;/mathjax&gt; where u = r / r_0 is our
non-dimensional distance measurement. And this is (up to some algebra)
exactly what we get in the initial&amp;nbsp;post.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Nobody Really Gets Quantum</title><link href="/posts/nobody-really-gets-quantum.html" rel="alternate"></link><updated>2010-04-22T14:29:00-04:00</updated><author><name>Yariv</name></author><id>tag:,2010-04-22:posts/nobody-really-gets-quantum.html</id><summary type="html">&lt;p&gt;Nobody Really Gets Quantum / &lt;a href="http://www.etgarkeret.com/"&gt;Etgar Keret&lt;/a&gt;
On &lt;a href="http://en.wikipedia.org/wiki/Yom_Kippur#Eve"&gt;Yom Kippur eve&lt;/a&gt; Quantum
walked over to Einstein&amp;#8217;s house to seek forgiveness. &amp;#8220;I&amp;#8217;m not home,&amp;#8221;
shouted Einstein from behind a closed door. On the way home people
taunted him and somebody even hit him with an empty can of coke. Quantum
pretended not to care, but deep inside he was really hurt. Nobody really
gets Quantum, everybody hates him. &amp;#8220;You parasite&amp;#8221; people cry out when
he&amp;#8217;s walking down the street, &amp;#8220;why are you dodging the draft?&amp;#8221; - &amp;#8220;I
wanted to enlist,&amp;#8221; Quantum tries to say, &amp;#8220;but they wouldn&amp;#8217;t take me,
because I&amp;#8217;m so small.&amp;#8221; Not that anybody listens to Quantum. Nobody
listens to Quantum when he tries to speak up for himself, but when he
says something that can be misconstrued, oh, then suddenly everybody&amp;#8217;s
paying attention. Quantum can say something innocent like &amp;#8220;wow, what a
cat!&amp;#8221; and right away the news says he&amp;#8217;s making provocations and run off
to talk to Schrodinger. And anyway, the media hates Quantum most,
because once when he was interviewed in Scientific American Quantum said
that the observer affects the observed event, and all the journalists
thought he was talking about the coverage of the
&lt;a href="http://en.wikipedia.org/wiki/First_Intifada"&gt;Intifada&lt;/a&gt; and claimed he
was deliberately inciting the masses. And Quantum can keep talking until
tomorrow about how he didn&amp;#8217;t mean it and he has no political
affiliation, nobody believes him anyway. Everybody knows he&amp;#8217;s friends
with &lt;a href="http://en.wikipedia.org/wiki/Yuval_Neeman#Political_career"&gt;Yuval
Ne&amp;#8217;eman.&lt;/a&gt; A
lot of people think Quantum is heartless, that he has no feelings, but
that&amp;#8217;s not true at all. On Friday, after a documentary on Hiroshima, he
was on the expert panel. And he couldn&amp;#8217;t even speak. Just sat in front
of the open mic and cried, and all of the viewers at home, that don&amp;#8217;t
really know Quantum, couldn&amp;#8217;t understand that Quantum was crying, they
just thought he was avoiding the question. And the sad thing about it
is, even if Quantum writes dozens of letters to the editors of all the
scientific journals in the world and proves beyond any doubt that for
the whole atomic bomb thing he was just being used and he never thought
it would end this way, it wouldn&amp;#8217;t help him, because nobody really gets
quantum. Least of all the physicists. from the original Hebrew by me;
posted without permission. Originally from &lt;a href="http://www.amazon.com/Girl-Fridge-Stories-Etgar-Keret/dp/0374531056/ref=sr_1_1?ie=UTF8&amp;amp;s=books&amp;amp;qid=1271963967&amp;amp;sr=8-1"&gt;The Girl on the
Fridge&lt;/a&gt;where
you can find somebody else&amp;#8217;s translation of this and other surreal short
stories by the very talented Etgar Keret. Incidentally, the original
story is written in the plural because in Hebrew we call quantum
mechanics, roughly, &amp;#8220;theory of the quantas;&amp;#8221; I switched it to singular
here because I think it works better this way in English. I&amp;#8217;m not sure
I&amp;#8217;ve done it justice - I&amp;#8217;m not sure you can actually do Keret&amp;#8217;s writing
justice reading it out of the Israeli cultural context (for instance,
many physicists will know Ne&amp;#8217;eman for his work on &lt;span class="caps"&gt;QCD&lt;/span&gt; but only Israelis
know he was politically active in a far-right party) - but I thought it
was worth a&amp;nbsp;shot.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Entropy and the Arrow of Time</title><link href="/posts/entropy-and-the-arrow-of-time.html" rel="alternate"></link><updated>2010-04-16T21:27:00-04:00</updated><author><name>Nik Zhelev</name></author><id>tag:,2010-04-16:posts/entropy-and-the-arrow-of-time.html</id><summary type="html">&lt;p&gt;Somebody I talked to yesterday about what should the topic of my post be
suggested that I should write something about cosmology, in particular
the Big Bang and the ultimate fate of the universe. Being mostly
interested in condensed matter, I am by no means an expert in cosmology
(I’ll leave that to Corky). However, I will not abandon the request, but
instead, spin it in a more condensed matter direction, by talking about
Entropy.
Entropy is a quantity that measures disorder. The more ordered your
system is, i.e. the less ways you can arrange the constituents of your
system, the less entropy you have and vice versa. I like to use the
example of how messy my room is to visualize this. When I clean my room,
I would pick up the random articles of clothing, books, etc and put them
in the places where they belong. Now imagine, I stopped cleaning my room
for a couple of weeks. This would result in clothes on the ground, books
on my bed, empty bottles on my desk, etc. anything can be anywhere. This
means that there are more ways for my personal belongings to be arranged
when my room is messy than when my room is clean (when everything would
be at its place), so the entropy increases as the messiness of my room
increases. Now, notice that left on its own (i.e. if I don’t put the
conscious effort to put some order in my room once in a while) the
entropy of the system that is my room increases with time. This is, in
fact, the essence of one of the most fundamental (if not the most
fundamental) laws of nature – The Second Law of Thermodynamics, which
states that left on its own, the entropy of any system increases with
time.
I know what you are thinking, “What does this talk about the messiness
of your room and the law of increasing entropy has to do with the
universe, the Big Bang and the universe’s ultimate fate?” Ok, here you
go, read this short story by the greatest sci-fi writer Isaac Asimov:
&lt;a href="http://bit.ly/84LN"&gt;The Last Question.&lt;/a&gt;
Now that you’ve read this story (if you haven’t, please do), we can
discuss some physics (or actually, some philosophy, but you know,
sometimes there isn’t that much difference between the two). Einstein,
with his Theory of Relativity, showed that the concept of time is not
absolute, and time can be treated simply as another coordinate, much
like the three spatial coordinates that define the three dimensional
space we are used to. (A more in-depth explanation of the Theory of
Relativity will be the topic of one of the next posts.) However, despite
the relativity of time, the arrow of time is always well-defined. We can
always tell future from past by measuring the entropy and applying the
Second Law of Thermodynamics. At the instance of the Big Bang, the
entropy was zero. Since then (about 13.8 billion years ago) the entropy
of the universe has been increasing until it will eventually reach its
maximum value, at which point all the matter of the universe would be
evenly distributed and no physical process would be possible. Time
eventually stops, resulting in the “heat death” of the universe.
I believe that one of the most unsettling parts of the Bing Bang theory
is the question of what caused the Big Bang, and what was there before
the Bing Bang. Having the arrow of time defined with regards to entropy,
however, makes this question nonsensical… unless, of course, a Cosmic &lt;span class="caps"&gt;AC&lt;/span&gt;
(or God) has managed to find the answer of how the entropy can be&amp;nbsp;reversed.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Physics for non-physicists</title><link href="/posts/physics-for-non-physicists.html" rel="alternate"></link><updated>2010-04-16T16:36:00-04:00</updated><author><name>Nik Zhelev</name></author><id>tag:,2010-04-16:posts/physics-for-non-physicists.html</id><summary type="html">&lt;p&gt;This is my first (but certainly not the last) post in this blog, so let
me introduce myself. My name is Nikolay, and as most of the others
contributing to the blog, I am also a first-year graduate student in
physics at Cornell.
So, what is my motivation to join the team headed by Mr. Alemi in
contributing to the blog? I happen to have many friends that are not in
physics. In fact, probably due to the fact that I graduated from a
liberal arts college, many of my friends have never taken any physics
beyond that one class in high school, which due to both the inherent
difficulty of teaching physics at introductory level and the lack of
good high school physics teachers was often an unpleasant experience
that scared them away from physics for life. Now, imagine what my
difficulty is when on a daily basis I have to answer the question: “So
what do you study/work on as a graduate student?” I usually try to come
up with a sentence or two describing the essence of what I am doing
without going into too many details, but even that is a daunting task.
There seems to be a disconnect between the world in which a physicist
lives and the general public. As Chad Orzel pointed out in the talk that
motivated the creation of this blog, this is not the general public’s
fault, but our fault as physicists of not really committing enough
effort in relating our knowledge to the rest of the world.
In short, my goal is to create a series of posts about physics geared to
people with no physics background that would build upon each other and
culminate with a post providing an answer to the question of what my
research project is beyond the generic words I would often resort to
that would rather leave most people confused. I plan to use as little
math as possible, which will not be an easy task considering that math
is the language of choice for physics. However, mathematics is just a
tool, and physics is not about equations and complicated algebra, but
about how nature works, which we should be able to formulate in plain
English. I know I am embarking on a difficult task, so wish me luck, and
please leave your thoughts in the remarks section of the blog, since any
feedback would be&amp;nbsp;appreciated.&lt;/p&gt;</summary><category term=""></category></entry></feed>